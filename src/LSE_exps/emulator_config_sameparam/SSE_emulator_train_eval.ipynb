{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69bc3ac-6d00-4f61-9b0e-d0fafb8fa3be",
   "metadata": {},
   "source": [
    "# compare the performance of emulator configurations based on iter-0 samples\n",
    "- SSE: Single-Site Emulator\n",
    "- SBE: Similarity-Based Emulator\n",
    "- LSE: Large-Sample Emulator\n",
    "\n",
    "Methods: \n",
    "- GPR: Gaussian Process Regression\n",
    "- RF: Random Forest\n",
    "- MLP: Multilayer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad96659-aeae-49da-a6ac-0d191f2d5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, pickle, toml, json, pickle, random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "sys.path.append('../../MOASMO_support')\n",
    "from MOASMO_parameter_allbasin_emulator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fd09b5b-a13a-43e0-ab22-a191c7131a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data function, taken from ~/CTSM_repos/CTSM_calibration/src/MOASMO_support/MOASMO_parameter_allbasin_emulator.py\n",
    "def load_basin_data():\n",
    "    infile_basin_info = f\"/glade/work/guoqiang/CTSM_CAMELS/data_mesh_surf/HillslopeHydrology/CAMELS_level1_basin_info.csv\"\n",
    "    infile_param_info = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/src/parameter/CTSM_CAMELS_calibparam_2410.csv'\n",
    "    infile_attr_foruse = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/data/camels_attributes_table_TrainModel.csv'\n",
    "    inpath_moasmo = \"/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator\"\n",
    "    path_CTSM_case = f'/glade/work/guoqiang/CTSM_CAMELS/Calib_HH_emulator'\n",
    "    iterend = 1 # only read data from iter-0\n",
    "    suffix = 'LSEnormKGE'\n",
    "    \n",
    "    outpath = f\"{inpath_moasmo}/LSE_allbasin\"\n",
    "    os.makedirs(outpath, exist_ok=True)\n",
    "    \n",
    "    # Load data: same for all iterations\n",
    "    df_basin_info = pd.read_csv(infile_basin_info)\n",
    "    df_param_info = pd.read_csv(infile_param_info)\n",
    "\n",
    "    all_index = np.arange(len(df_basin_info))\n",
    "    \n",
    "    file_defa_param = f'{outpath}/camels_627basin_ctsm_defa_param.csv'\n",
    "    df_param_defa = read_allbasin_defa_params(path_CTSM_case, infile_param_info, file_defa_param, len(df_basin_info))\n",
    "\n",
    "    file_param_lb = f'{outpath}/camels_627basin_ctsm_all_param_lb.gz'\n",
    "    file_param_ub = f'{outpath}/camels_627basin_ctsm_all_param_ub.gz'\n",
    "    df_param_lb, df_param_ub = load_basin_param_bounds(inpath_moasmo, df_param_defa, file_param_lb, file_param_ub, all_index, suffix)\n",
    "\n",
    "    file_camels_attribute = f'{outpath}/camels_627basin_attribute.pkl'\n",
    "    df_att = read_camels_attributes(infile_basin_info, file_camels_attribute, all_index)\n",
    "    \n",
    "    df_att_foruse = pd.read_csv(infile_attr_foruse)\n",
    "    useattrs = list(df_att_foruse[df_att_foruse['att_Xie2021'].values]['Attribute_text'].values)\n",
    "    print(\"The number of attributes used:\", len(useattrs))\n",
    "    print(useattrs)\n",
    "\n",
    "    # Load data: outputs from each iteration\n",
    "    for iter in range(0, iterend):\n",
    "        file_all_param = f'{outpath}/camels_627basin_ctsm_all_param_iter{iter}.gz'\n",
    "        file_all_metric = f'{outpath}/camels_627basin_ctsm_all_metric_iter{iter}.gz'\n",
    "        file_all_basinid = f'{outpath}/camels_627basin_ctsm_all_basinid_iter{iter}.gz'\n",
    "        \n",
    "        df_param_i, df_metric_i, df_basinid_i = load_all_basin_params_metrics(inpath_moasmo, df_param_defa, df_basin_info, iter, file_all_param, file_all_metric, file_all_basinid, all_index, suffix)\n",
    "        \n",
    "        df_basinid_i['iter'] = iter\n",
    "        \n",
    "        if iter == 0:\n",
    "            df_param = df_param_i\n",
    "            df_metric = df_metric_i\n",
    "            df_basinid = df_basinid_i\n",
    "        else:\n",
    "            df_param = pd.concat([df_param, df_param_i])\n",
    "            df_metric = pd.concat([df_metric, df_metric_i])\n",
    "            df_basinid = pd.concat([df_basinid, df_basinid_i])\n",
    "    \n",
    "    df_param.index = np.arange(len(df_param))\n",
    "    df_metric.index = np.arange(len(df_metric))\n",
    "    df_basinid.index = np.arange(len(df_basinid))\n",
    "\n",
    "    index = np.isnan(np.sum(df_metric.values, axis=1))\n",
    "    df_param = df_param[~index]\n",
    "    df_metric = df_metric[~index]\n",
    "    df_basinid = df_basinid[~index]\n",
    "    \n",
    "    df_param.index = np.arange(len(df_param))\n",
    "    df_metric.index = np.arange(len(df_metric))\n",
    "    df_basinid.index = np.arange(len(df_basinid))\n",
    "    \n",
    "    print('Number of nan samples:', np.sum(index))\n",
    "    print(\"Number of original parameter sets:\", len(index))\n",
    "    print(\"Number of final parameter sets:\", len(df_param))\n",
    "\n",
    "    return df_basin_info, df_param_info, df_param_defa, df_param_lb, df_param_ub, df_att, df_att_foruse, df_param, df_metric, df_basinid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60632706-b916-4fa5-97e3-f235e7f85eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cv(cv_results):\n",
    "    # evaluation\n",
    "    rmse_test = np.nan * np.zeros(len(cv_results))\n",
    "    rmse_train = np.nan * np.zeros(len(cv_results))\n",
    "    cc_test = np.nan * np.zeros(len(cv_results))\n",
    "    cc_train = np.nan * np.zeros(len(cv_results))\n",
    "    \n",
    "    for fold in range(1, len(cv_results)+1):\n",
    "        y_train, y_test, y_train_pred, y_test_pred = cv_results[fold]['y_train'], cv_results[fold]['y_test'], cv_results[fold]['y_train_pred'], cv_results[fold]['y_test_pred']\n",
    "        \n",
    "        # Evaluate the model using \n",
    "        rmse_test[fold - 1] = get_rmse(y_test, y_test_pred)\n",
    "        rmse_train[fold - 1] = get_rmse(y_train, y_train_pred)\n",
    "        cc_test[fold - 1] = get_cc(y_test, y_test_pred)\n",
    "        cc_train[fold - 1] = get_cc(y_train, y_train_pred)\n",
    "            \n",
    "    return rmse_test, rmse_train, cc_test, cc_train\n",
    "\n",
    "\n",
    "def get_rmse(d1, d2):\n",
    "    return ( np.nanmean( (d1-d2)**2 ) ) ** 0.5\n",
    "\n",
    "def get_cc(d1, d2):\n",
    "    ind = ~np.isnan(d1+d2)\n",
    "    return np.corrcoef(d1[ind], d2[ind])[0,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02bbd3-a3bd-4238-a4a5-653faf3e8d98",
   "metadata": {},
   "source": [
    "# Load data and save data for model training and comparison\n",
    "Here I just load the outputs from LSE which has summarized outputs from individual basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68038acc-0101-4def-9fa0-43c2ac0f230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_allbasin/camels_627basin_attribute.pkl\n",
      "The number of attributes used: 27\n",
      "['mean_elev', 'mean_slope', 'area_gauges2', 'p_mean', 'pet_mean', 'aridity', 'p_seasonality', 'frac_snow', 'high_prec_freq', 'high_prec_dur', 'low_prec_freq', 'low_prec_dur', 'frac_forest', 'lai_max', 'lai_diff', 'dom_land_cover', 'dom_land_cover_frac', 'soil_depth_pelletier', 'soil_depth_statsgo', 'soil_porosity', 'soil_conductivity', 'max_water_content', 'sand_frac', 'silt_frac', 'clay_frac', 'carbonate_rocks_frac', 'geol_permeability']\n",
      "Number of nan samples: 1363\n",
      "Number of original parameter sets: 125400\n",
      "Number of final parameter sets: 124037\n",
      "Number of basins: 627\n",
      "Number of all parameters: 16\n",
      "Number of all attributes: 62\n"
     ]
    }
   ],
   "source": [
    "# inpath = '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_MOASMO_bigrange/allbasin_emulator'\n",
    "\n",
    "# file_all_param = f'{inpath}/camels_627basin_ctsm_all_param_iter0.gz'\n",
    "# file_all_metric = f'{inpath}/camels_627basin_ctsm_all_meric_iter0.gz'\n",
    "# file_all_basinid = f'{inpath}/camels_627basin_ctsm_all_basinid_iter0.gz'\n",
    "\n",
    "# df_param = pd.read_csv(file_all_param, compression='gzip')\n",
    "# df_metric = pd.read_csv(file_all_metric, compression='gzip')\n",
    "# df_basinid = pd.read_csv(file_all_basinid, compression='gzip')\n",
    "\n",
    "\n",
    "\n",
    "df_basin_info, df_param_info, df_param_defa, df_param_lb, df_param_ub, df_att, df_att_foruse, df_param, df_metric, df_basinid = load_basin_data()\n",
    "print('Number of basins:', len(df_basin_info))\n",
    "print('Number of all parameters:', len(df_param_info))\n",
    "print('Number of all attributes:', len(df_att.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a53d8fd5-c165-4d98-a73b-5aa22d59431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath_moasmo = '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator'\n",
    "outpath_all = f'{inpath_moasmo}/LargeSampleEmulator_exps_out'\n",
    "os.makedirs(outpath_all, exist_ok=True)\n",
    "numbasin = len(df_basin_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "068ed895-907c-4baf-869b-47d61739f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = 15  # Example: Use 4 CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a69a7-c7dc-4f39-8070-9160eb31c57a",
   "metadata": {},
   "source": [
    "# SSE train and CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69c350-4f2c-4e4e-99ac-49a762017a37",
   "metadata": {},
   "source": [
    "## Train/Evaluate GPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828d80e3-c40e-4c64-9c66-a380ceaaf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serial version\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# path_MOASMO = '/glade/u/home/guoqiang/CTSM_repos/ctsm_optz/MO-ASMO/src/'\n",
    "# sys.path.append(path_MOASMO)\n",
    "# import sampling\n",
    "# import gp\n",
    "# import NSGA2\n",
    "\n",
    "# def gpr_emulator_cv(x, y, xlb_mean, xub_mean, rndseed=1234567890):\n",
    "    \n",
    "#     random.seed(rndseed)\n",
    "#     np.random.seed(rndseed)\n",
    "\n",
    "#     n_splits = 5\n",
    "#     alpha = 1e-3\n",
    "#     leng_lb = 1e-3\n",
    "#     leng_ub = 1e3\n",
    "#     nu = 2.5\n",
    "\n",
    "#     cv_results = {}\n",
    "        \n",
    "#     kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "#     kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "    \n",
    "#     for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "#         x_train, x_test = x[train_index], x[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "#         # Initialize and train your GPR model here; adjust parameters as needed\n",
    "#         sm = gp.GPR_Matern(x_train, y_train, x_train.shape[1], y_train.shape[1], x_train.shape[0], xlb_mean, xub_mean, alpha=alpha, leng_sb=[leng_lb, leng_ub], nu=nu)\n",
    "\n",
    "#         # Store results\n",
    "#         cv_results[fold_idx] = {\n",
    "#                 # 'model': bp_model,  # Optional: Comment this out to avoid large serialization\n",
    "#                 'train_index': train_index,\n",
    "#                 'test_index': test_index,\n",
    "#                 'y_train': np.squeeze(y_train),\n",
    "#                 'y_test': np.squeeze(y_test),\n",
    "#                 'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "#                 'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "#             }\n",
    "\n",
    "#     return cv_results\n",
    "\n",
    "\n",
    "# outfile = f'{outpath_all}/SSE_GPR_normKGE_CV_estimates.pkl'\n",
    "\n",
    "# # if os.path.isfile(outfile):\n",
    "# if False:\n",
    "#     with open(outfile, 'rb') as file:\n",
    "#         gpr_cv_results = pickle.load(file)\n",
    "    \n",
    "# else:\n",
    "#     gpr_cv_results = []\n",
    "#     for i in range(2):\n",
    "#         indi = df_basinid['basin_id'].values == i\n",
    "#         kgei = df_metric[indi]['kge'].values\n",
    "#         kgei = kgei / (2 - kgei)\n",
    "#         parami = df_param[indi].values\n",
    "    \n",
    "#         # only select useful params\n",
    "#         lbi = df_param_lb.iloc[i].values\n",
    "#         ubi = df_param_ub.iloc[i].values\n",
    "#         induse = lbi != ubi\n",
    "#         parami = parami[:, induse]\n",
    "#         lbi = lbi[induse]\n",
    "#         ubi = ubi[induse]\n",
    "    \n",
    "#         metrics_use = kgei[:,np.newaxis]\n",
    "        \n",
    "#         cv_results = gpr_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "#         gpr_cv_results.append(cv_results)\n",
    "\n",
    "#     with open(outfile, 'wb') as file:\n",
    "#         pickle.dump(gpr_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ad6973e-be1d-4639-94c5-75a71f57bae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 342 ms, sys: 216 ms, total: 558 ms\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel version\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "path_MOASMO = '/glade/u/home/guoqiang/CTSM_repos/ctsm_optz/MO-ASMO/src/'\n",
    "sys.path.append(path_MOASMO)\n",
    "import sampling\n",
    "import gp\n",
    "import NSGA2\n",
    "\n",
    "def gpr_emulator_cv(x, y, xlb_mean, xub_mean, rndseed=1234567890):\n",
    "    \n",
    "    random.seed(rndseed)\n",
    "    np.random.seed(rndseed)\n",
    "\n",
    "    n_splits = 5\n",
    "    alpha = 1e-3\n",
    "    leng_lb = 1e-3\n",
    "    leng_ub = 1e3\n",
    "    nu = 2.5\n",
    "\n",
    "    cv_results = {}\n",
    "        \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "    kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "    \n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and train your GPR model here; adjust parameters as needed\n",
    "        sm = gp.GPR_Matern(x_train, y_train, x_train.shape[1], y_train.shape[1], x_train.shape[0], xlb_mean, xub_mean, alpha=alpha, leng_sb=[leng_lb, leng_ub], nu=nu)\n",
    "\n",
    "        # Store results\n",
    "        cv_results[fold_idx] = {\n",
    "                'train_index': train_index,\n",
    "                'test_index': test_index,\n",
    "                'y_train': np.squeeze(y_train),\n",
    "                'y_test': np.squeeze(y_test),\n",
    "                'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "                'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "            }\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "def process_basin(i):\n",
    "    indi = df_basinid['basin_id'].values == i\n",
    "    kgei = df_metric[indi]['kge'].values\n",
    "    kgei = kgei / (2 - kgei)\n",
    "    parami = df_param[indi].values\n",
    "\n",
    "    # only select useful params\n",
    "    lbi = df_param_lb.iloc[i].values\n",
    "    ubi = df_param_ub.iloc[i].values\n",
    "    induse = lbi != ubi\n",
    "    parami = parami[:, induse]\n",
    "    lbi = lbi[induse]\n",
    "    ubi = ubi[induse]\n",
    "\n",
    "    metrics_use = kgei[:, np.newaxis]\n",
    "\n",
    "    cv_results = gpr_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "    return cv_results\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_GPR_normKGE_CV_estimates.pkl'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    with open(outfile, 'rb') as file:\n",
    "        gpr_cv_results = pickle.load(file)\n",
    "else:\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        gpr_cv_results = pool.map(process_basin, range(numbasin))\n",
    "\n",
    "    with open(outfile, 'wb') as file:\n",
    "        pickle.dump(gpr_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d04dc8a-e49f-4867-abe0-11749fc08f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 546 ms, sys: 8.27 ms, total: 554 ms\n",
      "Wall time: 590 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# evaluate GPR CV\n",
    "\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_GPR_normKGE_CV_evaluation.npz'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    dtmp = np.load(outfile)\n",
    "    gpr_rmse_train = dtmp['gpr_rmse_train']\n",
    "    gpr_rmse_test = dtmp['gpr_rmse_test']\n",
    "    gpr_cc_train = dtmp['gpr_cc_train']\n",
    "    gpr_cc_test = dtmp['gpr_cc_test']\n",
    "\n",
    "else:\n",
    "\n",
    "    gpr_rmse_train = np.nan * np.zeros([numbasin, 5])\n",
    "    gpr_rmse_test = np.nan * np.zeros([numbasin, 5])\n",
    "    gpr_cc_train = np.nan * np.zeros([numbasin, 5])\n",
    "    gpr_cc_test = np.nan * np.zeros([numbasin, 5])    \n",
    "    for i in range(len(gpr_cv_results)):\n",
    "        gpr_rmse_test[i, :], gpr_rmse_train[i, :], gpr_cc_test[i, :], gpr_cc_train[i, :] = evaluate_cv(gpr_cv_results[i])\n",
    "\n",
    "    np.savez_compressed(outfile, gpr_rmse_train=gpr_rmse_train, gpr_rmse_test=gpr_rmse_test, gpr_cc_train=gpr_cc_train, gpr_cc_test=gpr_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dca7c5-5f69-48b1-b7a8-1f8954a0f8b8",
   "metadata": {},
   "source": [
    "## Train/Evalute RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfe7493d-f816-4c3d-8b3a-8bbee1f61c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 309 ms, sys: 190 ms, total: 498 ms\n",
      "Wall time: 53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel version\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def rf_emulator_cv(x, y, xlb_mean, xub_mean):\n",
    "\n",
    "    random.seed(1234567890)\n",
    "    np.random.seed(1234567890)\n",
    "    \n",
    "    n_splits = 5\n",
    "\n",
    "    cv_results = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "    kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "\n",
    "\n",
    "    # normalize\n",
    "    x = (x - xlb_mean) / (xub_mean - xlb_mean)\n",
    "\n",
    "    \n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and train your GPR model here; adjust parameters as needed\n",
    "        sm = RandomForestRegressor()\n",
    "        sm.fit(x_train, y_train)\n",
    "        \n",
    "        # Store results\n",
    "        cv_results[fold_idx] = {\n",
    "                'train_index': train_index,\n",
    "                'test_index': test_index,\n",
    "                'y_train': np.squeeze(y_train),\n",
    "                'y_test': np.squeeze(y_test),\n",
    "                'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "                'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "            }\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def process_basin(i):\n",
    "    indi = df_basinid['basin_id'].values == i\n",
    "    kgei = df_metric[indi]['kge'].values\n",
    "    kgei = kgei / (2 - kgei)\n",
    "    parami = df_param[indi].values\n",
    "\n",
    "    # only select useful params\n",
    "    lbi = df_param_lb.iloc[i].values\n",
    "    ubi = df_param_ub.iloc[i].values\n",
    "    induse = lbi != ubi\n",
    "    parami = parami[:, induse]\n",
    "    lbi = lbi[induse]\n",
    "    ubi = ubi[induse]\n",
    "\n",
    "    metrics_use = kgei[:, np.newaxis]\n",
    "\n",
    "    cv_results = rf_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "    return cv_results\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_RF_normKGE_CV_estimates.pkl'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    with open(outfile, 'rb') as file:\n",
    "        rf_cv_results = pickle.load(file)\n",
    "else:\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        rf_cv_results = pool.map(process_basin, range(numbasin))\n",
    "\n",
    "    with open(outfile, 'wb') as file:\n",
    "        pickle.dump(rf_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8998446d-f2b8-41b0-afeb-59fcf2194cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "outfile = f'{outpath_all}/SSE_RF_normKGE_CV_evaluation.npz'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    dtmp = np.load(outfile)\n",
    "    rf_rmse_train = dtmp['rf_rmse_train']\n",
    "    rf_rmse_test = dtmp['rf_rmse_test']\n",
    "    rf_cc_train = dtmp['rf_cc_train']\n",
    "    rf_cc_test = dtmp['rf_cc_test']\n",
    "\n",
    "else:\n",
    "\n",
    "    rf_rmse_train = np.nan * np.zeros([numbasin, 5])\n",
    "    rf_rmse_test = np.nan * np.zeros([numbasin, 5])\n",
    "    rf_cc_train = np.nan * np.zeros([numbasin, 5])\n",
    "    rf_cc_test = np.nan * np.zeros([numbasin, 5])    \n",
    "    for i in range(len(rf_cv_results)):\n",
    "        rf_rmse_test[i, :], rf_rmse_train[i, :], rf_cc_test[i, :], rf_cc_train[i, :] = evaluate_cv(rf_cv_results[i])\n",
    "\n",
    "    np.savez_compressed(outfile, rf_rmse_train=rf_rmse_train, rf_rmse_test=rf_rmse_test, rf_cc_train=rf_cc_train, rf_cc_test=rf_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80799d92-2123-4bef-aabd-90a5f268b42f",
   "metadata": {},
   "source": [
    "## Train/Evaluate MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e7b2caf-e43b-4044-b18b-c055217a78aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 452 ms, sys: 1.06 s, total: 1.51 s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel version\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def mlp_emulator_cv(x, y, xlb_mean, xub_mean):\n",
    "\n",
    "    random.seed(1234567890)\n",
    "    np.random.seed(1234567890)\n",
    "    \n",
    "    n_splits = 5\n",
    "\n",
    "    cv_results = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "    kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "\n",
    "\n",
    "    # normalize\n",
    "    x = (x - xlb_mean) / (xub_mean - xlb_mean)\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and train your GPR model here; adjust parameters as needed\n",
    "        # sm = make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(2000,)))\n",
    "        sm = make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(2000,),  alpha=0.9))\n",
    "        sm.fit(x_train, y_train)\n",
    "\n",
    "        # Store results\n",
    "        cv_results[fold_idx] = {\n",
    "                'train_index': train_index,\n",
    "                'test_index': test_index,\n",
    "                'y_train': np.squeeze(y_train),\n",
    "                'y_test': np.squeeze(y_test),\n",
    "                'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "                'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "            }\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def process_basin(i):\n",
    "    indi = df_basinid['basin_id'].values == i\n",
    "    kgei = df_metric[indi]['kge'].values\n",
    "    kgei = kgei / (2 - kgei)\n",
    "    parami = df_param[indi].values\n",
    "\n",
    "    # only select useful params\n",
    "    lbi = df_param_lb.iloc[i].values\n",
    "    ubi = df_param_ub.iloc[i].values\n",
    "    induse = lbi != ubi\n",
    "    parami = parami[:, induse]\n",
    "    lbi = lbi[induse]\n",
    "    ubi = ubi[induse]\n",
    "\n",
    "    metrics_use = kgei[:, np.newaxis]\n",
    "\n",
    "    cv_results = mlp_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "    return cv_results\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_MLP_normKGE_CV_estimates.pkl'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    with open(outfile, 'rb') as file:\n",
    "        mlp_cv_results = pickle.load(file)\n",
    "else:\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        mlp_cv_results = pool.map(process_basin, range(numbasin))\n",
    "\n",
    "    with open(outfile, 'wb') as file:\n",
    "        pickle.dump(mlp_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24cfdb69-df54-41ce-be8b-87a4dcc4ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "outfile = f'{outpath_all}/SSE_MLP_normKGE_CV_evaluation.npz'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    dtmp = np.load(outfile)\n",
    "    mlp_rmse_train = dtmp['mlp_rmse_train']\n",
    "    mlp_rmse_test = dtmp['mlp_rmse_test']\n",
    "    mlp_cc_train = dtmp['mlp_cc_train']\n",
    "    mlp_cc_test = dtmp['mlp_cc_test']\n",
    "\n",
    "else:\n",
    "\n",
    "    mlp_rmse_train = np.nan * np.zeros([numbasin, 5])\n",
    "    mlp_rmse_test = np.nan * np.zeros([numbasin, 5])\n",
    "    mlp_cc_train = np.nan * np.zeros([numbasin, 5])\n",
    "    mlp_cc_test = np.nan * np.zeros([numbasin, 5])    \n",
    "    for i in range(len(mlp_cv_results)):\n",
    "        mlp_rmse_test[i, :], mlp_rmse_train[i, :], mlp_cc_test[i, :], mlp_cc_train[i, :] = evaluate_cv(mlp_cv_results[i])\n",
    "\n",
    "    np.savez_compressed(outfile, mlp_rmse_train=mlp_rmse_train, mlp_rmse_test=mlp_rmse_test, mlp_cc_train=mlp_cc_train, mlp_cc_test=mlp_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70665fe7-80ed-481f-be51-040d83282e76",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0f28e56-d0ac-4063-81bb-faad869573ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse train/test 0.007561693379490421 0.16987473102450223\n",
      "mean cc train/test 0.9980582181770596 0.5489312298987348\n"
     ]
    }
   ],
   "source": [
    "print('mean rmse train/test', np.nanmean(gpr_rmse_train), np.nanmean(gpr_rmse_test) )\n",
    "print('mean cc train/test', np.nanmean(gpr_cc_train), np.nanmean(gpr_cc_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ae3d4d-08f2-48d2-904e-9f8f2cd41169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse train/test 0.048653727934877725 0.12874976711901526\n",
      "mean cc train/test 0.9787458583157571 0.7374902235879119\n"
     ]
    }
   ],
   "source": [
    "print('mean rmse train/test', np.nanmean(rf_rmse_train), np.nanmean(rf_rmse_test) )\n",
    "print('mean cc train/test', np.nanmean(rf_cc_train), np.nanmean(rf_cc_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e47edcf-2210-4100-bc8a-2676043aa2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse train/test 0.0555952837454648 0.17180624482524046\n",
      "mean cc train/test 0.9694944984471124 0.5463971982377617\n"
     ]
    }
   ],
   "source": [
    "print('mean rmse train/test', np.nanmean(mlp_rmse_train), np.nanmean(mlp_rmse_test) )\n",
    "print('mean cc train/test', np.nanmean(mlp_cc_train), np.nanmean(mlp_cc_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3931ac4-41ba-43e0-9571-c1ce14eacd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16736359350448454, 0.12561362837687706, 0.16895591852446032)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmedian(gpr_rmse_test), np.nanmedian(rf_rmse_test), np.nanmedian(mlp_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b31a7d64-76c8-4312-be8e-d32bc434b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio that gpr+rf is better than mlp 0.9968102073365231\n",
      "ratio gpr is better than rf 0.014354066985645933\n",
      "ratio gpr is better than mlp 0.6172248803827751\n",
      "ratio rf is better than mlp 0.988835725677831\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this means combining gpr + rf is always better than ann\n",
    "\n",
    "gpr_rmse_m = np.nanmean(gpr_rmse_test, axis=1)\n",
    "rf_rmse_m = np.nanmean(rf_rmse_test, axis=1)\n",
    "mlp_rmse_m = np.nanmean(mlp_rmse_test, axis=1)\n",
    "\n",
    "ind = (gpr_rmse_m<mlp_rmse_m) | (rf_rmse_m<mlp_rmse_m)\n",
    "print('ratio that gpr+rf is better than mlp', np.sum(ind)/numbasin)\n",
    "print('ratio gpr is better than rf', np.sum(gpr_rmse_m < rf_rmse_m)/numbasin)\n",
    "print('ratio gpr is better than mlp', np.sum(gpr_rmse_m < mlp_rmse_m)/numbasin)\n",
    "print('ratio rf is better than mlp', np.sum(rf_rmse_m < mlp_rmse_m)/numbasin)\n",
    "\n",
    "gpr_rmse_m = np.nanmean(gpr_rmse_test, axis=1)\n",
    "rf_rmse_m = np.nanmean(rf_rmse_test, axis=1)\n",
    "mlp_rmse_m = np.nanmean(mlp_rmse_test, axis=1)\n",
    "\n",
    "plt.hist(gpr_rmse_m, alpha=0.3, label='gpr')\n",
    "plt.hist(rf_rmse_m, alpha=0.3, label='rf')\n",
    "plt.hist(mlp_rmse_m, alpha=0.3, label='mlp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60f31a-6302-4d85-b9df-db3fe627f617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f18e49-bae2-42ee-a9f7-a39505a9a1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:npl-2024a-tgq]",
   "language": "python",
   "name": "conda-env-npl-2024a-tgq-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
