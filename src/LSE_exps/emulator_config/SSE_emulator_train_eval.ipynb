{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69bc3ac-6d00-4f61-9b0e-d0fafb8fa3be",
   "metadata": {},
   "source": [
    "# compare the performance of emulator configurations based on iter-0 samples\n",
    "- SSE: Single-Site Emulator\n",
    "- SBE: Similarity-Based Emulator\n",
    "- LSE: Large-Sample Emulator\n",
    "\n",
    "Methods: \n",
    "- GPR: Gaussian Process Regression\n",
    "- RF: Random Forest\n",
    "- MLP: Multilayer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad96659-aeae-49da-a6ac-0d191f2d5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, pickle, toml, json, pickle, random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "sys.path.append('../../MOASMO_support')\n",
    "from MOASMO_parameter_allbasin_emulator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd09b5b-a13a-43e0-ab22-a191c7131a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data function, taken from ~/CTSM_repos/CTSM_calibration/src/MOASMO_support/MOASMO_parameter_allbasin_emulator.py\n",
    "def load_basin_data():\n",
    "    infile_basin_info = f\"/glade/work/guoqiang/CTSM_CAMELS/data_mesh_surf/HillslopeHydrology/CAMELS_level1_basin_info.csv\"\n",
    "    infile_param_info = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/src/parameter/CTSM_CAMELS_SA_param_240202.csv'\n",
    "    infile_attr_foruse = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/data/camels_attributes_table_TrainModel.csv'\n",
    "    inpath_moasmo = \"/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_MOASMO_bigrange\"\n",
    "    path_CTSM_case = f'/glade/work/guoqiang/CTSM_CAMELS/Calib_HH_MOASMO_bigrange'\n",
    "    iterend = 1 # only read data from iter-0\n",
    "\n",
    "    outpath = f\"{inpath_moasmo}/allbasin_emulator\"\n",
    "    os.makedirs(outpath, exist_ok=True)\n",
    "    \n",
    "    # Load data: same for all iterations\n",
    "    df_basin_info = pd.read_csv(infile_basin_info)\n",
    "    df_param_info = pd.read_csv(infile_param_info)\n",
    "    \n",
    "    file_defa_param = f'{outpath}/camels_627basin_ctsm_defa_param.csv'\n",
    "    df_param_defa = read_allbasin_defa_params(path_CTSM_case, infile_param_info, file_defa_param, len(df_basin_info))\n",
    "\n",
    "    file_param_lb = f'{outpath}/camels_627basin_ctsm_all_param_lb.gz'\n",
    "    file_param_ub = f'{outpath}/camels_627basin_ctsm_all_param_ub.gz'\n",
    "    df_param_lb, df_param_ub = load_basin_param_bounds(inpath_moasmo, df_param_defa, file_param_lb, file_param_ub)\n",
    "\n",
    "    file_camels_attribute = f'{outpath}/camels_627basin_attribute.pkl'\n",
    "    df_att = read_camels_attributes(infile_basin_info, file_camels_attribute)\n",
    "    \n",
    "    df_att_foruse = pd.read_csv(infile_attr_foruse)\n",
    "    useattrs = list(df_att_foruse[df_att_foruse['att_Xie2021'].values]['Attribute_text'].values)\n",
    "    print(\"The number of attributes used:\", len(useattrs))\n",
    "    print(useattrs)\n",
    "\n",
    "    # Load data: outputs from each iteration\n",
    "    for iter in range(0, iterend):\n",
    "        file_all_param = f'{outpath}/camels_627basin_ctsm_all_param_iter{iter}.gz'\n",
    "        file_all_metric = f'{outpath}/camels_627basin_ctsm_all_metric_iter{iter}.gz'\n",
    "        file_all_basinid = f'{outpath}/camels_627basin_ctsm_all_basinid_iter{iter}.gz'\n",
    "        \n",
    "        df_param_i, df_metric_i, df_basinid_i = load_all_basin_params_metrics(inpath_moasmo, df_param_defa, df_basin_info, iter, file_all_param, file_all_metric, file_all_basinid)\n",
    "        \n",
    "        df_basinid_i['iter'] = iter\n",
    "        \n",
    "        if iter == 0:\n",
    "            df_param = df_param_i\n",
    "            df_metric = df_metric_i\n",
    "            df_basinid = df_basinid_i\n",
    "        else:\n",
    "            df_param = pd.concat([df_param, df_param_i])\n",
    "            df_metric = pd.concat([df_metric, df_metric_i])\n",
    "            df_basinid = pd.concat([df_basinid, df_basinid_i])\n",
    "    \n",
    "    df_param.index = np.arange(len(df_param))\n",
    "    df_metric.index = np.arange(len(df_metric))\n",
    "    df_basinid.index = np.arange(len(df_basinid))\n",
    "\n",
    "    index = np.isnan(np.sum(df_metric.values, axis=1))\n",
    "    df_param = df_param[~index]\n",
    "    df_metric = df_metric[~index]\n",
    "    df_basinid = df_basinid[~index]\n",
    "    \n",
    "    df_param.index = np.arange(len(df_param))\n",
    "    df_metric.index = np.arange(len(df_metric))\n",
    "    df_basinid.index = np.arange(len(df_basinid))\n",
    "    \n",
    "    print('Number of nan samples:', np.sum(index))\n",
    "    print(\"Number of original parameter sets:\", len(index))\n",
    "    print(\"Number of final parameter sets:\", len(df_param))\n",
    "\n",
    "    return df_basin_info, df_param_info, df_param_defa, df_param_lb, df_param_ub, df_att, df_att_foruse, df_param, df_metric, df_basinid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60632706-b916-4fa5-97e3-f235e7f85eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cv(cv_results):\n",
    "    # evaluation\n",
    "    rmse_test = np.nan * np.zeros(len(cv_results))\n",
    "    rmse_train = np.nan * np.zeros(len(cv_results))\n",
    "    cc_test = np.nan * np.zeros(len(cv_results))\n",
    "    cc_train = np.nan * np.zeros(len(cv_results))\n",
    "    \n",
    "    for fold in range(1, len(cv_results)+1):\n",
    "        y_train, y_test, y_train_pred, y_test_pred = cv_results[fold]['y_train'], cv_results[fold]['y_test'], cv_results[fold]['y_train_pred'], cv_results[fold]['y_test_pred']\n",
    "        \n",
    "        # Evaluate the model using \n",
    "        rmse_test[fold - 1] = get_rmse(y_test, y_test_pred)\n",
    "        rmse_train[fold - 1] = get_rmse(y_train, y_train_pred)\n",
    "        cc_test[fold - 1] = get_cc(y_test, y_test_pred)\n",
    "        cc_train[fold - 1] = get_cc(y_train, y_train_pred)\n",
    "            \n",
    "    return rmse_test, rmse_train, cc_test, cc_train\n",
    "\n",
    "\n",
    "def get_rmse(d1, d2):\n",
    "    return ( np.nanmean( (d1-d2)**2 ) ) ** 0.5\n",
    "\n",
    "def get_cc(d1, d2):\n",
    "    ind = ~np.isnan(d1+d2)\n",
    "    return np.corrcoef(d1[ind], d2[ind])[0,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02bbd3-a3bd-4238-a4a5-653faf3e8d98",
   "metadata": {},
   "source": [
    "# Load data and save data for model training and comparison\n",
    "Here I just load the outputs from LSE which has summarized outputs from individual basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68038acc-0101-4def-9fa0-43c2ac0f230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_MOASMO_bigrange/allbasin_emulator/camels_627basin_attribute.pkl\n",
      "The number of attributes used: 27\n",
      "['mean_elev', 'mean_slope', 'area_gauges2', 'p_mean', 'pet_mean', 'aridity', 'p_seasonality', 'frac_snow', 'high_prec_freq', 'high_prec_dur', 'low_prec_freq', 'low_prec_dur', 'frac_forest', 'lai_max', 'lai_diff', 'dom_land_cover', 'dom_land_cover_frac', 'soil_depth_pelletier', 'soil_depth_statsgo', 'soil_porosity', 'soil_conductivity', 'max_water_content', 'sand_frac', 'silt_frac', 'clay_frac', 'carbonate_rocks_frac', 'geol_permeability']\n",
      "Number of nan samples: 3309\n",
      "Number of original parameter sets: 250800\n",
      "Number of final parameter sets: 247491\n",
      "Number of basins: 627\n",
      "Number of all parameters: 27\n",
      "Number of all attributes: 62\n"
     ]
    }
   ],
   "source": [
    "# inpath = '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_MOASMO_bigrange/allbasin_emulator'\n",
    "\n",
    "# file_all_param = f'{inpath}/camels_627basin_ctsm_all_param_iter0.gz'\n",
    "# file_all_metric = f'{inpath}/camels_627basin_ctsm_all_meric_iter0.gz'\n",
    "# file_all_basinid = f'{inpath}/camels_627basin_ctsm_all_basinid_iter0.gz'\n",
    "\n",
    "# df_param = pd.read_csv(file_all_param, compression='gzip')\n",
    "# df_metric = pd.read_csv(file_all_metric, compression='gzip')\n",
    "# df_basinid = pd.read_csv(file_all_basinid, compression='gzip')\n",
    "\n",
    "df_basin_info, df_param_info, df_param_defa, df_param_lb, df_param_ub, df_att, df_att_foruse, df_param, df_metric, df_basinid = load_basin_data()\n",
    "print('Number of basins:', len(df_basin_info))\n",
    "print('Number of all parameters:', len(df_param_info))\n",
    "print('Number of all attributes:', len(df_att.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53d8fd5-c165-4d98-a73b-5aa22d59431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath_moasmo = '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_MOASMO_bigrange'\n",
    "outpath_all = f'{inpath_moasmo}/LargeSampleEmulator_exps_out'\n",
    "os.makedirs(outpath_all, exist_ok=True)\n",
    "numbasin = len(df_basin_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068ed895-907c-4baf-869b-47d61739f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = 1  # Example: Use 4 CPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8a69a7-c7dc-4f39-8070-9160eb31c57a",
   "metadata": {},
   "source": [
    "# SSE train and CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69c350-4f2c-4e4e-99ac-49a762017a37",
   "metadata": {},
   "source": [
    "## Train/Evaluate GPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828d80e3-c40e-4c64-9c66-a380ceaaf563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serial version\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# path_MOASMO = '/glade/u/home/guoqiang/CTSM_repos/ctsm_optz/MO-ASMO/src/'\n",
    "# sys.path.append(path_MOASMO)\n",
    "# import sampling\n",
    "# import gp\n",
    "# import NSGA2\n",
    "\n",
    "# def gpr_emulator_cv(x, y, xlb_mean, xub_mean, rndseed=1234567890):\n",
    "    \n",
    "#     random.seed(rndseed)\n",
    "#     np.random.seed(rndseed)\n",
    "\n",
    "#     n_splits = 5\n",
    "#     alpha = 1e-3\n",
    "#     leng_lb = 1e-3\n",
    "#     leng_ub = 1e3\n",
    "#     nu = 2.5\n",
    "\n",
    "#     cv_results = {}\n",
    "        \n",
    "#     kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "#     kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "    \n",
    "#     for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "#         x_train, x_test = x[train_index], x[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "#         # Initialize and train your GPR model here; adjust parameters as needed\n",
    "#         sm = gp.GPR_Matern(x_train, y_train, x_train.shape[1], y_train.shape[1], x_train.shape[0], xlb_mean, xub_mean, alpha=alpha, leng_sb=[leng_lb, leng_ub], nu=nu)\n",
    "\n",
    "#         # Store results\n",
    "#         cv_results[fold_idx] = {\n",
    "#                 # 'model': bp_model,  # Optional: Comment this out to avoid large serialization\n",
    "#                 'train_index': train_index,\n",
    "#                 'test_index': test_index,\n",
    "#                 'y_train': np.squeeze(y_train),\n",
    "#                 'y_test': np.squeeze(y_test),\n",
    "#                 'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "#                 'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "#             }\n",
    "\n",
    "#     return cv_results\n",
    "\n",
    "\n",
    "# outfile = f'{outpath_all}/SSE_GPR_normKGE_CV_estimates.pkl'\n",
    "\n",
    "# # if os.path.isfile(outfile):\n",
    "# if False:\n",
    "#     with open(outfile, 'rb') as file:\n",
    "#         gpr_cv_results = pickle.load(file)\n",
    "    \n",
    "# else:\n",
    "#     gpr_cv_results = []\n",
    "#     for i in range(2):\n",
    "#         indi = df_basinid['basin_id'].values == i\n",
    "#         kgei = df_metric[indi]['kge'].values\n",
    "#         kgei = kgei / (2 - kgei)\n",
    "#         parami = df_param[indi].values\n",
    "    \n",
    "#         # only select useful params\n",
    "#         lbi = df_param_lb.iloc[i].values\n",
    "#         ubi = df_param_ub.iloc[i].values\n",
    "#         induse = lbi != ubi\n",
    "#         parami = parami[:, induse]\n",
    "#         lbi = lbi[induse]\n",
    "#         ubi = ubi[induse]\n",
    "    \n",
    "#         metrics_use = kgei[:,np.newaxis]\n",
    "        \n",
    "#         cv_results = gpr_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "#         gpr_cv_results.append(cv_results)\n",
    "\n",
    "#     with open(outfile, 'wb') as file:\n",
    "#         pickle.dump(gpr_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad6973e-be1d-4639-94c5-75a71f57bae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.6 ms, sys: 16.3 ms, total: 60.9 ms\n",
      "Wall time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel version\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "path_MOASMO = '/glade/u/home/guoqiang/CTSM_repos/ctsm_optz/MO-ASMO/src/'\n",
    "sys.path.append(path_MOASMO)\n",
    "import sampling\n",
    "import gp\n",
    "import NSGA2\n",
    "\n",
    "def gpr_emulator_cv(x, y, xlb_mean, xub_mean, rndseed=1234567890):\n",
    "    \n",
    "    random.seed(rndseed)\n",
    "    np.random.seed(rndseed)\n",
    "\n",
    "    n_splits = 5\n",
    "    alpha = 1e-3\n",
    "    leng_lb = 1e-3\n",
    "    leng_ub = 1e3\n",
    "    nu = 2.5\n",
    "\n",
    "    cv_results = {}\n",
    "        \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "    kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "    \n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and train your GPR model here; adjust parameters as needed\n",
    "        sm = gp.GPR_Matern(x_train, y_train, x_train.shape[1], y_train.shape[1], x_train.shape[0], xlb_mean, xub_mean, alpha=alpha, leng_sb=[leng_lb, leng_ub], nu=nu)\n",
    "\n",
    "        # Store results\n",
    "        cv_results[fold_idx] = {\n",
    "                'train_index': train_index,\n",
    "                'test_index': test_index,\n",
    "                'y_train': np.squeeze(y_train),\n",
    "                'y_test': np.squeeze(y_test),\n",
    "                'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "                'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "            }\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "def process_basin(i):\n",
    "    indi = df_basinid['basin_id'].values == i\n",
    "    kgei = df_metric[indi]['kge'].values\n",
    "    kgei = kgei / (2 - kgei)\n",
    "    parami = df_param[indi].values\n",
    "\n",
    "    # only select useful params\n",
    "    lbi = df_param_lb.iloc[i].values\n",
    "    ubi = df_param_ub.iloc[i].values\n",
    "    induse = lbi != ubi\n",
    "    parami = parami[:, induse]\n",
    "    lbi = lbi[induse]\n",
    "    ubi = ubi[induse]\n",
    "\n",
    "    metrics_use = kgei[:, np.newaxis]\n",
    "\n",
    "    cv_results = gpr_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "    return cv_results\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_GPR_normKGE_CV_estimates.pkl'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    with open(outfile, 'rb') as file:\n",
    "        gpr_cv_results = pickle.load(file)\n",
    "else:\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        gpr_cv_results = pool.map(process_basin, range(numbasin))\n",
    "\n",
    "    with open(outfile, 'wb') as file:\n",
    "        pickle.dump(gpr_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d04dc8a-e49f-4867-abe0-11749fc08f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.43 ms, sys: 0 ns, total: 3.43 ms\n",
      "Wall time: 30.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# evaluate GPR CV\n",
    "\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_GPR_normKGE_CV_evaluation.npz'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    dtmp = np.load(outfile)\n",
    "    gpr_rmse_train = dtmp['gpr_rmse_train']\n",
    "    gpr_rmse_test = dtmp['gpr_rmse_test']\n",
    "    gpr_cc_train = dtmp['gpr_cc_train']\n",
    "    gpr_cc_test = dtmp['gpr_cc_test']\n",
    "\n",
    "else:\n",
    "\n",
    "    gpr_rmse_train = np.nan * np.zeros([numbasin, 5])\n",
    "    gpr_rmse_test = np.nan * np.zeros([numbasin, 5])\n",
    "    gpr_cc_train = np.nan * np.zeros([numbasin, 5])\n",
    "    gpr_cc_test = np.nan * np.zeros([numbasin, 5])    \n",
    "    for i in range(len(gpr_cv_results)):\n",
    "        gpr_rmse_test[i, :], gpr_rmse_train[i, :], gpr_cc_test[i, :], gpr_cc_train[i, :] = evaluate_cv(gpr_cv_results[i])\n",
    "\n",
    "    np.savez_compressed(outfile, gpr_rmse_train=gpr_rmse_train, gpr_rmse_test=gpr_rmse_test, gpr_cc_train=gpr_cc_train, gpr_cc_test=gpr_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dca7c5-5f69-48b1-b7a8-1f8954a0f8b8",
   "metadata": {},
   "source": [
    "## Train/Evalute RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe7493d-f816-4c3d-8b3a-8bbee1f61c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 47.8 ms, sys: 17.2 ms, total: 65 ms\n",
      "Wall time: 258 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel version\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def rf_emulator_cv(x, y, xlb_mean, xub_mean):\n",
    "\n",
    "    random.seed(1234567890)\n",
    "    np.random.seed(1234567890)\n",
    "    \n",
    "    n_splits = 5\n",
    "\n",
    "    cv_results = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "    kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "\n",
    "\n",
    "    # normalize\n",
    "    x = (x - xlb_mean) / (xub_mean - xlb_mean)\n",
    "\n",
    "    \n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and train your GPR model here; adjust parameters as needed\n",
    "        sm = RandomForestRegressor()\n",
    "        sm.fit(x_train, y_train)\n",
    "        \n",
    "        # Store results\n",
    "        cv_results[fold_idx] = {\n",
    "                'train_index': train_index,\n",
    "                'test_index': test_index,\n",
    "                'y_train': np.squeeze(y_train),\n",
    "                'y_test': np.squeeze(y_test),\n",
    "                'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "                'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "            }\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def process_basin(i):\n",
    "    indi = df_basinid['basin_id'].values == i\n",
    "    kgei = df_metric[indi]['kge'].values\n",
    "    kgei = kgei / (2 - kgei)\n",
    "    parami = df_param[indi].values\n",
    "\n",
    "    # only select useful params\n",
    "    lbi = df_param_lb.iloc[i].values\n",
    "    ubi = df_param_ub.iloc[i].values\n",
    "    induse = lbi != ubi\n",
    "    parami = parami[:, induse]\n",
    "    lbi = lbi[induse]\n",
    "    ubi = ubi[induse]\n",
    "\n",
    "    metrics_use = kgei[:, np.newaxis]\n",
    "\n",
    "    cv_results = rf_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "    return cv_results\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_RF_normKGE_CV_estimates.pkl'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    with open(outfile, 'rb') as file:\n",
    "        rf_cv_results = pickle.load(file)\n",
    "else:\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        rf_cv_results = pool.map(process_basin, range(numbasin))\n",
    "\n",
    "    with open(outfile, 'wb') as file:\n",
    "        pickle.dump(rf_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8998446d-f2b8-41b0-afeb-59fcf2194cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "outfile = f'{outpath_all}/SSE_RF_normKGE_CV_evaluation.npz'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    dtmp = np.load(outfile)\n",
    "    rf_rmse_train = dtmp['rf_rmse_train']\n",
    "    rf_rmse_test = dtmp['rf_rmse_test']\n",
    "    rf_cc_train = dtmp['rf_cc_train']\n",
    "    rf_cc_test = dtmp['rf_cc_test']\n",
    "\n",
    "else:\n",
    "\n",
    "    rf_rmse_train = np.nan * np.zeros([numbasin, 5])\n",
    "    rf_rmse_test = np.nan * np.zeros([numbasin, 5])\n",
    "    rf_cc_train = np.nan * np.zeros([numbasin, 5])\n",
    "    rf_cc_test = np.nan * np.zeros([numbasin, 5])    \n",
    "    for i in range(len(rf_cv_results)):\n",
    "        rf_rmse_test[i, :], rf_rmse_train[i, :], rf_cc_test[i, :], rf_cc_train[i, :] = evaluate_cv(rf_cv_results[i])\n",
    "\n",
    "    np.savez_compressed(outfile, rf_rmse_train=rf_rmse_train, rf_rmse_test=rf_rmse_test, rf_cc_train=rf_cc_train, rf_cc_test=rf_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80799d92-2123-4bef-aabd-90a5f268b42f",
   "metadata": {},
   "source": [
    "## Train/Evaluate MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e7b2caf-e43b-4044-b18b-c055217a78aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.4 ms, sys: 28 ms, total: 78.3 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel version\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def mlp_emulator_cv(x, y, xlb_mean, xub_mean):\n",
    "\n",
    "    random.seed(1234567890)\n",
    "    np.random.seed(1234567890)\n",
    "    \n",
    "    n_splits = 5\n",
    "\n",
    "    cv_results = {}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True) \n",
    "    kge_scores = np.nan * np.zeros([n_splits, y.shape[1]])\n",
    "\n",
    "\n",
    "    # normalize\n",
    "    x = (x - xlb_mean) / (xub_mean - xlb_mean)\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(x), 1):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and train your GPR model here; adjust parameters as needed\n",
    "        # sm = make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(2000,)))\n",
    "        sm = make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(2000,),  alpha=0.9))\n",
    "        sm.fit(x_train, y_train)\n",
    "\n",
    "        # Store results\n",
    "        cv_results[fold_idx] = {\n",
    "                'train_index': train_index,\n",
    "                'test_index': test_index,\n",
    "                'y_train': np.squeeze(y_train),\n",
    "                'y_test': np.squeeze(y_test),\n",
    "                'y_test_pred': np.squeeze(sm.predict(x_test)),\n",
    "                'y_train_pred': np.squeeze(sm.predict(x_train)),\n",
    "            }\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def process_basin(i):\n",
    "    indi = df_basinid['basin_id'].values == i\n",
    "    kgei = df_metric[indi]['kge'].values\n",
    "    kgei = kgei / (2 - kgei)\n",
    "    parami = df_param[indi].values\n",
    "\n",
    "    # only select useful params\n",
    "    lbi = df_param_lb.iloc[i].values\n",
    "    ubi = df_param_ub.iloc[i].values\n",
    "    induse = lbi != ubi\n",
    "    parami = parami[:, induse]\n",
    "    lbi = lbi[induse]\n",
    "    ubi = ubi[induse]\n",
    "\n",
    "    metrics_use = kgei[:, np.newaxis]\n",
    "\n",
    "    cv_results = mlp_emulator_cv(parami, metrics_use, lbi, ubi)\n",
    "    return cv_results\n",
    "\n",
    "outfile = f'{outpath_all}/SSE_MLP_normKGE_CV_estimates.pkl'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    with open(outfile, 'rb') as file:\n",
    "        mlp_cv_results = pickle.load(file)\n",
    "else:\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_cpus) as pool:\n",
    "        mlp_cv_results = pool.map(process_basin, range(numbasin))\n",
    "\n",
    "    with open(outfile, 'wb') as file:\n",
    "        pickle.dump(mlp_cv_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24cfdb69-df54-41ce-be8b-87a4dcc4ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "outfile = f'{outpath_all}/SSE_MLP_normKGE_CV_evaluation.npz'\n",
    "\n",
    "if os.path.isfile(outfile):\n",
    "    dtmp = np.load(outfile)\n",
    "    mlp_rmse_train = dtmp['mlp_rmse_train']\n",
    "    mlp_rmse_test = dtmp['mlp_rmse_test']\n",
    "    mlp_cc_train = dtmp['mlp_cc_train']\n",
    "    mlp_cc_test = dtmp['mlp_cc_test']\n",
    "\n",
    "else:\n",
    "\n",
    "    mlp_rmse_train = np.nan * np.zeros([numbasin, 5])\n",
    "    mlp_rmse_test = np.nan * np.zeros([numbasin, 5])\n",
    "    mlp_cc_train = np.nan * np.zeros([numbasin, 5])\n",
    "    mlp_cc_test = np.nan * np.zeros([numbasin, 5])    \n",
    "    for i in range(len(mlp_cv_results)):\n",
    "        mlp_rmse_test[i, :], mlp_rmse_train[i, :], mlp_cc_test[i, :], mlp_cc_train[i, :] = evaluate_cv(mlp_cv_results[i])\n",
    "\n",
    "    np.savez_compressed(outfile, mlp_rmse_train=mlp_rmse_train, mlp_rmse_test=mlp_rmse_test, mlp_cc_train=mlp_cc_train, mlp_cc_test=mlp_cc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70665fe7-80ed-481f-be51-040d83282e76",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0f28e56-d0ac-4063-81bb-faad869573ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse train/test 0.01602375177474596 0.07449462442358838\n",
      "mean cc train/test 0.9717979920443841 0.7913423940296098\n"
     ]
    }
   ],
   "source": [
    "print('mean rmse train/test', np.nanmean(gpr_rmse_train), np.nanmean(gpr_rmse_test) )\n",
    "print('mean cc train/test', np.nanmean(gpr_cc_train), np.nanmean(gpr_cc_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21ae3d4d-08f2-48d2-904e-9f8f2cd41169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse train/test 0.027107613013837416 0.07219663558870755\n",
      "mean cc train/test 0.9838820472249656 0.8071012348527201\n"
     ]
    }
   ],
   "source": [
    "print('mean rmse train/test', np.nanmean(rf_rmse_train), np.nanmean(rf_rmse_test) )\n",
    "print('mean cc train/test', np.nanmean(rf_cc_train), np.nanmean(rf_cc_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e47edcf-2210-4100-bc8a-2676043aa2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse train/test 0.04896116147480786 0.07109251325483687\n",
      "mean cc train/test 0.9175851974621652 0.8092091741775724\n"
     ]
    }
   ],
   "source": [
    "print('mean rmse train/test', np.nanmean(mlp_rmse_train), np.nanmean(mlp_rmse_test) )\n",
    "print('mean cc train/test', np.nanmean(mlp_cc_train), np.nanmean(mlp_cc_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3931ac4-41ba-43e0-9571-c1ce14eacd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05882821565184366, 0.061725544671725335, 0.06030343379000705)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmedian(gpr_rmse_test), np.nanmedian(rf_rmse_test), np.nanmedian(mlp_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31a7d64-76c8-4312-be8e-d32bc434b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio that gpr+rf is better than mlp 0.7400318979266348\n",
      "ratio gpr is better than rf 0.5263157894736842\n",
      "ratio gpr is better than mlp 0.47527910685805425\n",
      "ratio rf is better than mlp 0.4178628389154705\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this means combining gpr + rf is always better than ann\n",
    "\n",
    "gpr_rmse_m = np.nanmean(gpr_rmse_test, axis=1)\n",
    "rf_rmse_m = np.nanmean(rf_rmse_test, axis=1)\n",
    "mlp_rmse_m = np.nanmean(mlp_rmse_test, axis=1)\n",
    "\n",
    "ind = (gpr_rmse_m<mlp_rmse_m) | (rf_rmse_m<mlp_rmse_m)\n",
    "print('ratio that gpr+rf is better than mlp', np.sum(ind)/numbasin)\n",
    "print('ratio gpr is better than rf', np.sum(gpr_rmse_m < rf_rmse_m)/numbasin)\n",
    "print('ratio gpr is better than mlp', np.sum(gpr_rmse_m < mlp_rmse_m)/numbasin)\n",
    "print('ratio rf is better than mlp', np.sum(rf_rmse_m < mlp_rmse_m)/numbasin)\n",
    "\n",
    "gpr_rmse_m = np.nanmean(gpr_rmse_test, axis=1)\n",
    "rf_rmse_m = np.nanmean(rf_rmse_test, axis=1)\n",
    "mlp_rmse_m = np.nanmean(mlp_rmse_test, axis=1)\n",
    "\n",
    "plt.hist(gpr_rmse_m, alpha=0.3, label='gpr')\n",
    "plt.hist(rf_rmse_m, alpha=0.3, label='rf')\n",
    "plt.hist(mlp_rmse_m, alpha=0.3, label='mlp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60f31a-6302-4d85-b9df-db3fe627f617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f18e49-bae2-42ee-a9f7-a39505a9a1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:npl-2024a-tgq]",
   "language": "python",
   "name": "conda-env-npl-2024a-tgq-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
