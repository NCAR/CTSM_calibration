{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0832a8d8-8f46-4e05-a18b-d910d1bbc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, sys, toml, pickle, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from os import path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "path_MOASMO = '/glade/u/home/guoqiang/CTSM_repos/ctsm_optz/MO-ASMO/src/'\n",
    "sys.path.append(path_MOASMO)\n",
    "import gp\n",
    "import NSGA2\n",
    "\n",
    "\n",
    "import os, sys, subprocess, time, toml\n",
    "\n",
    "sys.path.append(\"/glade/u/home/mozhgana/mywork/model_calibration/src/moasmo_test/\")\n",
    "sys.path.append(\"/glade/u/home/mozhgana/mywork/model_calibration/src/moasmo_test/allbasin_emulator\")\n",
    "from MOASMO_parameter_allbasin_emulator import *\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "sys.path.append(\"/glade/u/home/guoqiang/CTSM_repos/ctsm_optz/MO-ASMO/src\")\n",
    "# import NSGA2\n",
    "\n",
    "\n",
    "from MOASMO_parameters import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328a96ac-d5de-4773-9631-9fd01ff304ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_basin_info = '/glade/work/guoqiang/CTSM_CAMELS/data_mesh_surf/HillslopeHydrology/CAMELS_level1_basin_info.csv'\n",
    "infile_param_info = '/glade/u/home/mozhgana/mywork/model_calibration/src/moasmo_test/param_file_tpl.csv'\n",
    "infile_attr_foruse = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/data/camels_attributes_table_TrainModel.csv'\n",
    "inpath_moasmo = '/glade/campaign/cgd/tss/people/mozhgana/projects/SUMMA_Calib'\n",
    "\n",
    "CV=1\n",
    "ncpus = 1\n",
    "iterend = 1\n",
    "outpathname = 'LSE_spaceCV_PredictParam_4X_ann'\n",
    "suffix = f'LSEspaceCV_ann_{CV}'\n",
    "objfunc = 'normKGE'\n",
    "numruns = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca70c71-7449-4117-8871-597faba71f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV=1\n",
    "outpath = '/glade/campaign/cgd/tss/people/mozhgana/projects/SUMMA_Calib/LSE_spaceCV_PredictParam'\n",
    "# divide into train/test index\n",
    "outfile = f'{outpath}/train_test_CV_indices.npz'\n",
    "if os.path.isfile(outfile):\n",
    "    dtmp = np.load(outfile, allow_pickle=True)\n",
    "    train_indices, test_indices = dtmp['train_indices'], dtmp['test_indices']\n",
    "\n",
    "train_index= train_indices[CV-1]\n",
    "test_index= test_indices[CV-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0fd2e9f-af47-4d5e-93a0-c3c31763494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /glade/campaign/cgd/tss/people/mozhgana/projects/SUMMA_Calib/LSE_spaceCV_PredictParam_4X_ann/camels_basin_attribute_train_LSEspaceCV_ann_1.pkl\n",
      "File exists: /glade/campaign/cgd/tss/people/mozhgana/projects/SUMMA_Calib/LSE_spaceCV_PredictParam_4X_ann/camels_basin_attribute_test_LSEspaceCV_ann_1.pkl\n",
      "The number of attributes used: 27\n",
      "['mean_elev', 'mean_slope', 'area_gauges2', 'p_mean', 'pet_mean', 'aridity', 'p_seasonality', 'frac_snow', 'high_prec_freq', 'high_prec_dur', 'low_prec_freq', 'low_prec_dur', 'frac_forest', 'lai_max', 'lai_diff', 'dom_land_cover', 'dom_land_cover_frac', 'soil_depth_pelletier', 'soil_depth_statsgo', 'soil_porosity', 'soil_conductivity', 'max_water_content', 'sand_frac', 'silt_frac', 'clay_frac', 'carbonate_rocks_frac', 'geol_permeability']\n",
      "Number of nan samples: 406\n",
      "Number of original parameter sets: 200400\n",
      "Number of final parameter sets: 199994\n",
      "Convert dom_land_cover to one-hot encoding\n",
      "New columns: ['dom_land_cover_0', 'dom_land_cover_1', 'dom_land_cover_2', 'dom_land_cover_3', 'dom_land_cover_4', 'dom_land_cover_5', 'dom_land_cover_6', 'dom_land_cover_7', 'dom_land_cover_8', 'dom_land_cover_9', 'dom_land_cover_10', 'dom_land_cover_11']\n",
      "Input shape: (199994, 52)\n"
     ]
    }
   ],
   "source": [
    "suffix_defa_source = 'LSEnormKGE'\n",
    "\n",
    "outpath = f\"{inpath_moasmo}/{outpathname}\"\n",
    "os.makedirs(outpath, exist_ok=True)\n",
    "\n",
    "# Load data: same for all iterations\n",
    "df_basin_info = pd.read_csv(infile_basin_info)\n",
    "df_basin_info.index = np.arange(len(df_basin_info))\n",
    "all_index = np.arange(len(df_basin_info))\n",
    "\n",
    "test_index = np.setdiff1d(all_index, train_index)\n",
    "\n",
    "# information for all basins\n",
    "df_param_info = pd.read_csv(infile_param_info)\n",
    "\n",
    "file_defa_param = f'{outpath}/camels_summa_defa_param_train_{suffix}.csv'\n",
    "df_param_defa_train = read_allbasin_defa_params(infile_param_info, file_defa_param, Basin_list, train_index)\n",
    "\n",
    "file_defa_param = f'{outpath}/camels_summa_defa_param_test_{suffix}.csv'\n",
    "df_param_defa_test = read_allbasin_defa_params(infile_param_info, file_defa_param, Basin_list, test_index)\n",
    "\n",
    "file_param_lb = f'{outpath}/camels_summa_all_param_lb_train_{suffix}.gz'\n",
    "file_param_ub = f'{outpath}/camels_summa_all_param_ub_train_{suffix}.gz'\n",
    "\n",
    "df_param_lb_train, df_param_ub_train = load_basin_param_bounds(inpath_moasmo, df_param_defa_train, file_param_lb, file_param_ub)\n",
    "\n",
    "file_param_lb = f'{outpath}/camels_summa_all_param_lb_test_{suffix}.gz'\n",
    "file_param_ub = f'{outpath}/camels_summa_all_param_ub_test_{suffix}.gz'\n",
    "df_param_lb_test, df_param_ub_test = load_basin_param_bounds(inpath_moasmo, df_param_defa_test, file_param_lb, file_param_ub)\n",
    "\n",
    "\n",
    "file_camels_attribute = f'{outpath}/camels_basin_attribute_train_{suffix}.pkl'\n",
    "df_att_train = read_camels_attributes(infile_basin_info, file_camels_attribute, train_index)\n",
    "file_camels_attribute = f'{outpath}/camels_basin_attribute_test_{suffix}.pkl'\n",
    "df_att_test = read_camels_attributes(infile_basin_info, file_camels_attribute, test_index)\n",
    "\n",
    "df_att_foruse = pd.read_csv(infile_attr_foruse)\n",
    "useattrs = list(df_att_foruse[df_att_foruse['att_Xie2021'].values]['Attribute_text'].values)\n",
    "print(\"The number of attributes used:\", len(useattrs))\n",
    "print(useattrs)\n",
    "\n",
    "\n",
    "suffixtest = suffix+'test'\n",
    "\n",
    "# Load data: outputs from each iteration from training basins\n",
    "for iter in range(0, iterend):\n",
    "    file_all_param = f'{outpath}/camels_summa_all_param_train_{suffix}_iter{iter}.gz'\n",
    "    file_all_metric = f'{outpath}/camels_summa_all_metric_train_{suffix}_iter{iter}.gz'\n",
    "    file_all_basinid = f'{outpath}/camels_summa_all_basinid_train_{suffix}_iter{iter}.gz'\n",
    "\n",
    "    file_all_param_test = f'{outpath}/camels_summa_all_param_test_{suffix}_iter{iter}.gz'\n",
    "    file_all_metric_test = f'{outpath}/camels_summa_all_metric_test_{suffix}_iter{iter}.gz'\n",
    "    file_all_basinid_test = f'{outpath}/camels_summa_all_basinid_test_{suffix}_iter{iter}.gz'\n",
    "\n",
    "    if iter == 0:\n",
    "\n",
    "        df_param_i, df_metric_i, df_basinid_i = load_all_basin_params_metrics(inpath_moasmo, infile_param_info, df_param_defa_train,\n",
    "                                                                              df_basin_info, iter, file_all_param,\n",
    "                                                                              file_all_metric, file_all_basinid,\n",
    "                                                                              train_index, suffix_defa_source)\n",
    "    \n",
    "        df_param_i_test, df_metric_i_test, df_basinid_i_test = load_all_basin_params_metrics(inpath_moasmo, infile_param_info, df_param_defa_test,\n",
    "                                                                              df_basin_info, iter, file_all_param_test,\n",
    "                                                                              file_all_metric_test, file_all_basinid_test,\n",
    "                                                                              test_index, suffix_defa_source)\n",
    "    else:\n",
    "        df_param_i, df_metric_i, df_basinid_i = load_all_basin_params_metrics(inpath_moasmo, infile_param_info, df_param_defa_train,\n",
    "                                                                              df_basin_info, iter, file_all_param,\n",
    "                                                                              file_all_metric, file_all_basinid,\n",
    "                                                                              train_index, suffix)\n",
    "    \n",
    "        df_param_i_test, df_metric_i_test, df_basinid_i_test = load_all_basin_params_metrics(inpath_moasmo, infile_param_info, df_param_defa_test,\n",
    "                                                                              df_basin_info, iter, file_all_param_test,\n",
    "                                                                              file_all_metric_test, file_all_basinid_test,\n",
    "                                                                              test_index, suffixtest)\n",
    "\n",
    "    df_basinid_i['iter'] = iter\n",
    "    df_basinid_i_test['iter'] = iter\n",
    "\n",
    "    if iter == 0:\n",
    "        df_param = df_param_i\n",
    "        df_metric = df_metric_i\n",
    "        df_basinid = df_basinid_i\n",
    "        \n",
    "        df_param_test = df_param_i_test\n",
    "        df_metric_test = df_metric_i_test\n",
    "        df_basinid_test = df_basinid_i_test\n",
    "    else:\n",
    "        df_param = pd.concat([df_param, df_param_i])\n",
    "        df_metric = pd.concat([df_metric, df_metric_i])\n",
    "        df_basinid = pd.concat([df_basinid, df_basinid_i])\n",
    "        \n",
    "        df_param_test = pd.concat([df_param_test, df_param_i_test])\n",
    "        df_metric_test = pd.concat([df_metric_test, df_metric_i_test])        \n",
    "        df_basinid_test = pd.concat([df_basinid_test, df_basinid_i_test])\n",
    "\n",
    "df_param = df_param.apply(pd.to_numeric, errors='coerce')\n",
    "df_param_test = df_param_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "df_param.index = np.arange(len(df_param))\n",
    "df_metric.index = np.arange(len(df_metric))\n",
    "df_basinid.index = np.arange(len(df_basinid))\n",
    "\n",
    "df_param_test.index = np.arange(len(df_param_test))\n",
    "df_metric_test.index = np.arange(len(df_metric_test))\n",
    "df_basinid_test.index = np.arange(len(df_basinid_test))\n",
    "\n",
    "\n",
    "index = np.isnan(np.sum(df_metric.values, axis=1) + np.sum(df_param.values, axis=1))\n",
    "df_param = df_param[~index]\n",
    "df_metric = df_metric[~index]\n",
    "df_basinid = df_basinid[~index]\n",
    "\n",
    "index_test = np.isnan(np.sum(df_metric_test.values, axis=1) + np.sum(df_param_test.values, axis=1))\n",
    "df_param_test = df_param_test[~index_test]\n",
    "df_metric_test = df_metric_test[~index_test]\n",
    "df_basinid_test = df_basinid_test[~index_test]\n",
    "\n",
    "\n",
    "df_param.index = np.arange(len(df_param))\n",
    "df_metric.index = np.arange(len(df_metric))\n",
    "df_basinid.index = np.arange(len(df_basinid))\n",
    "\n",
    "df_param_test.index = np.arange(len(df_param_test))\n",
    "df_metric_test.index = np.arange(len(df_metric_test))\n",
    "df_basinid_test.index = np.arange(len(df_basinid_test))\n",
    "\n",
    "\n",
    "print('Number of nan samples:', np.sum(index))\n",
    "print(\"Number of original parameter sets:\", len(index))\n",
    "print(\"Number of final parameter sets:\", len(df_param))\n",
    "\n",
    "\n",
    "# One-hot encoding for categorical attributes\n",
    "df_att = pd.concat([df_att_train, df_att_test])\n",
    "df_att.index = np.arange(len(df_att))\n",
    "df_att_use = df_att[useattrs + [\"hru_id\"]]\n",
    "\n",
    "for att in useattrs:\n",
    "    if df_att_use[att].dtype == \"object\":\n",
    "        print('Convert', att, 'to one-hot encoding')\n",
    "        enc = OneHotEncoder(sparse_output=False)\n",
    "        enc.fit(df_att_use[[att]])\n",
    "        encnames = [att + \"_\" + str(i) for i in range(len(enc.categories_[0]))]\n",
    "        print('New columns:', encnames)\n",
    "        df_enc = pd.DataFrame(enc.transform(df_att_use[[att]]), columns=encnames)\n",
    "        df_att_use = pd.concat([df_att_use, df_enc], axis=1)\n",
    "        df_att_use = df_att_use.drop([att], axis=1)\n",
    "\n",
    "df_att_use_train = df_att_use[:len(df_att_train)]\n",
    "df_att_use_test = df_att_use[len(df_att_train):]\n",
    "df_att_use_train.index = np.arange(len(df_att_use_train))\n",
    "df_att_use_test.index = np.arange(len(df_att_use_test))\n",
    "\n",
    "useattrs = list(df_att_use_train.columns)\n",
    "useattrs.remove('hru_id')\n",
    "\n",
    "useattrs_test = list(df_att_use_test.columns)\n",
    "useattrs_test.remove('hru_id')\n",
    "\n",
    "# Prepare model input and output\n",
    "df_input = df_param.copy()\n",
    "df_input[\"hru_id\"] = df_basinid[\"basin_name\"]\n",
    "df_input = df_input.merge(df_att_use_train[useattrs + [\"hru_id\"]], on=\"hru_id\", how=\"left\")\n",
    "df_input = df_input.drop([\"hru_id\"], axis=1)\n",
    "\n",
    "inputnames = list(df_param.columns) + useattrs\n",
    "x_all = df_input[inputnames].values.copy()\n",
    "print(\"Input shape:\", x_all.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b5199b-6132-41df-9888-6d3598b7fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Normalize the features\n",
    "    x_train_mean = np.mean(x_all, axis=0)\n",
    "    x_train_std = np.std(x_all, axis=0)    \n",
    "    x_all_scaled = (x_all - x_train_mean) / x_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "763baf02-ca8d-466e-a373-5923903ce64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use normalized KGE as output\n"
     ]
    }
   ],
   "source": [
    "    if objfunc == 'normKGE':\n",
    "        print('Use normalized KGE as output')\n",
    "        df_output = df_metric.copy()\n",
    "        y_all = df_output[[\"kge\"]].values.copy()\n",
    "        y_all = y_all / (2 - y_all)  # Normalize KGE\n",
    "\n",
    "        # File path to save or load the model\n",
    "        outfile = f'/glade/derecho/scratch/guoqiang/MLP_emulator_for_iter{iterend}_{suffix}.pkl'\n",
    "        \n",
    "        # Check if the model file exists\n",
    "        if os.path.isfile(outfile):\n",
    "            # Load the existing model\n",
    "            with open(outfile, 'rb') as file:\n",
    "                em_model = pickle.load(file)\n",
    "        else:\n",
    "            # Model configuration for MLP\n",
    "            modelconfig = {\n",
    "                'hidden_layer_sizes': (100, 100),\n",
    "                'max_iter': 1000,\n",
    "                'alpha': 0.001,\n",
    "                'random_state': 42,\n",
    "                'early_stopping': True,\n",
    "                'validation_fraction': 0.1,  # 10% internal validation for early stopping\n",
    "                'n_iter_no_change': 10\n",
    "            }\n",
    "        \n",
    "            # Initialize and train the model\n",
    "            em_model = MLPRegressor(**modelconfig)\n",
    "            em_model.fit(x_all_scaled, y_all)\n",
    "        \n",
    "            # Save the trained model\n",
    "            with open(outfile, 'wb') as file:\n",
    "                pickle.dump(em_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27de9a75-bdfc-4511-aa4a-e2f8ef745087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/guoqiang/conda-envs/PytorchEnv/lib/python3.11/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=40, n_estimators=200, n_jobs=1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=40, n_estimators=200, n_jobs=1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=40, n_estimators=200, n_jobs=1, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "            modelconfig = {'n_estimators': 200, 'random_state': 42, 'max_depth': 40}\n",
    "            em_model = RandomForestRegressor(**modelconfig, n_jobs=ncpus)\n",
    "            em_model.fit(x_all_scaled, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "964028bf-90b6-4bcb-8308-1aacc0c4ecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04822202284487172)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all_predict = em_model.predict(x_all_scaled)\n",
    "np.sqrt(np.mean( (np.squeeze(y_all_predict)-np.squeeze(y_all))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5adb2b9-0b7b-4034-b47c-d6a506b4a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # normdict = {'method': 'z-score',\n",
    "    #             'mean': x_train_mean,\n",
    "    #             'std': x_train_std,\n",
    "    #            }\n",
    "    # param_names = df_param_info['Parameter'].values\n",
    "    # parallel_process_basins_norm(df_basinid, df_param_lb_train, df_param_ub_train,\n",
    "    #                         x_all, df_input, y_all,\n",
    "    #                         param_names, inputnames, em_model, inpath_moasmo, ncpus, numruns, iterend, train_index, suffix, normdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d01117-2fc5-4ed8-b783-f76a69303506",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #### predict parameter in unseen basins\n",
    "    suffixtest = suffix+'test'\n",
    "    numruns_test = 1 # can be smaller\n",
    "    if objfunc == 'normKGE':\n",
    "        num_objfunc=1\n",
    "    else:\n",
    "        sys.exit('Not tested objfunc')\n",
    "\n",
    "    df_att_use_test2 = df_att_use_test.drop(['hru_id'], axis=1)\n",
    "\n",
    "    xlb_mean_test = np.nan * np.zeros([len(df_param_lb_test), len(inputnames)])\n",
    "    xub_mean_test = np.nan * np.zeros([len(df_param_ub_test), len(inputnames)])   \n",
    "    for i in range(len(df_param_lb_test)):\n",
    "        param_lb_mean = df_param_lb_test.values[i, :]\n",
    "        param_ub_mean = df_param_ub_test.values[i, :]\n",
    "        attrvalues = df_att_use_test2.values[i,:]\n",
    "        xlb_mean_test[i,:] = np.hstack([param_lb_mean, attrvalues])\n",
    "        xub_mean_test[i,:] = np.hstack([param_ub_mean, attrvalues])\n",
    "\n",
    "    xlb_mean_test_scaled = (xlb_mean_test - x_train_mean) / x_train_std\n",
    "    xub_mean_test_scaled = (xub_mean_test - x_train_mean) / x_train_std\n",
    "    normdict = {'method': 'z-score',\n",
    "                'mean': x_train_mean,\n",
    "                'std': x_train_std,\n",
    "               }\n",
    "    \n",
    "    # parallel_process_basins_predictunseen_norm(xlb_mean_test_scaled, xub_mean_test_scaled, param_names, em_model, inpath_moasmo, ncpus, numruns_test, iterend, test_index, suffixtest, num_objfunc, normdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b2e2d2-647d-40c1-bb8e-72bb8e19086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    times = 100\n",
    "    param_names = df_param_info['Parameter'].values\n",
    "    df_basinid, xlb_mean_all, xub_mean_all, param_names, em_model, inpath_moasmo, ncpus, numruns, iterend, basin_index, suffix, num_objfunc, normdict = df_basinid_test, xlb_mean_test_scaled, xub_mean_test_scaled, param_names, em_model, inpath_moasmo, ncpus, numruns_test, iterend, test_index, suffixtest, num_objfunc, normdict\n",
    "    args = [(basin_index[tarbasin_id], tarbasin_id, df_basinid, em_model, xlb_mean_all[tarbasin_id, :], xub_mean_all[tarbasin_id, :], \n",
    "                 param_names, inpath_moasmo, numruns, iterend, suffix, num_objfunc, normdict, times) \n",
    "                for tarbasin_id in range(len(basin_index))]\n",
    "\n",
    "    tarbasin, tarbasin_id, df_basinid, em_model, xlb_mean, xub_mean, param_names, inpath_moasmo, numruns, iterend, suffix, num_objfunc, normdict, times = args[0]\n",
    "\n",
    "    basin_id= str(int(df_basinid.loc[df_basinid['basin_id'] == tarbasin, 'basin_name'].values[0]))\n",
    "    if len(basin_id) == 7:\n",
    "        basin_id = '0' + basin_id\n",
    "\n",
    "    basin_id, em_model, xlb_mean, xub_mean, param_names, inpath_moasmo, numruns, iterend, suffix, num_objfunc, normdict, times = basin_id, em_model, xlb_mean, xub_mean, param_names, inpath_moasmo, numruns, iterend, suffix, num_objfunc, normdict, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2a2887-6bda-4541-bbe4-3a57d7dd30a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run GA 10 times and extract the best 1 solutions\n",
      "reverse normalization\n",
      "finish basin 01013500\n"
     ]
    }
   ],
   "source": [
    "    basin_id = str(basin_id)\n",
    "\n",
    "    # Check if the hru_id needs a leading zero (it should be 8 characters long)\n",
    "    if len(basin_id) == 7:\n",
    "        basin_id = '0' + basin_id\n",
    "    \n",
    "    # outpath = f'{inpath_moasmo}/param_sets_{suffix}/{basin_id}/'\n",
    "    # os.makedirs(outpath, exist_ok=True)\n",
    "\n",
    "    if num_objfunc == 1:\n",
    "        ga_all_solutions, ga_all_outputs = run_ga_optimization(em_model, xlb_mean, xub_mean, num_runs=numruns, pop_size=100, num_generations=100, times=10)\n",
    "        # outfile_ga = f'{outpath}/ga_output_iter{iterend}.npz'\n",
    "        # if os.path.isfile(outfile_ga):\n",
    "        #     dtmp = np.load(outfile_ga)\n",
    "        #     ga_all_solutions = dtmp['ga_all_solutions']\n",
    "        #     ga_all_outputs = dtmp['ga_all_outputs']\n",
    "        # else:\n",
    "        #     ga_all_solutions, ga_all_outputs = run_ga_optimization(em_model, xlb_mean, xub_mean, num_runs=numruns, pop_size=100, num_generations=100, times=times)\n",
    "        #     np.savez_compressed(outfile_ga, ga_all_solutions=ga_all_solutions, ga_all_outputs=ga_all_outputs)\n",
    "    \n",
    "        final_solutions_array = np.array(ga_all_solutions)\n",
    "\n",
    "    # elif num_objfunc == 2:\n",
    "    #     outfile_nsga2 = f'{outpath}/nsga2_output_iter{iterend}.npz'\n",
    "    #     if os.path.isfile(outfile_nsga2):\n",
    "    #         dtmp = np.load(outfile_nsga2)\n",
    "    #         nsga2_all_solutions = dtmp['nsga2_all_solutions']\n",
    "    #         nsga2_all_outputs = dtmp['nsga2_all_outputs']\n",
    "    #     else:\n",
    "    #         nsga2_all_solutions, nsga2_all_outputs = run_nsga2_optimization(em_model, xlb_mean, xub_mean, num_runs=numruns, pop_size=100, num_generations=100)\n",
    "    #         np.savez_compressed(outfile_nsga2, nsga2_all_solutions=nsga2_all_solutions, nsga2_all_outputs=nsga2_all_outputs)\n",
    "    \n",
    "    #     final_solutions_array = np.array(nsga2_all_solutions)\n",
    "    \n",
    "    df_info = pd.read_csv(f'{inpath_moasmo}/param_sets/{basin_id}/paramset_iter0_trial0.csv').loc[:13,:]\n",
    "    df_info = df_info.loc[df_info['Value'] != 'None']\n",
    "    \n",
    "    df_info['Factor'] = np.nan\n",
    "    df_info['Value'] = np.nan\n",
    "\n",
    "    indexp = [np.where(param_names == p)[0][0] for p in df_info['Parameter'].values if p in param_names]\n",
    "\n",
    "    # reverse normalization\n",
    "    if 'method' in normdict:\n",
    "        if normdict['method'] == 'z-score':\n",
    "            print('reverse normalization')\n",
    "            final_solutions_array = final_solutions_array*normdict['std'] + normdict['mean']\n",
    "\n",
    "\n",
    "    # Read heightCanopyBottom from the file\n",
    "    paramfile = f'/glade/campaign/cgd/tss/people/mozhgana/projects/SUMMA/settings/{basin_id}/trialParams.camels.nc'\n",
    "    dataset = Dataset(paramfile)\n",
    "    height_canopy_bottom_value = dataset.variables['heightCanopyBottom'][:][0]\n",
    "\n",
    "    for i in range(final_solutions_array.shape[0]):\n",
    "        outfile = f'{outpath}/paramset_iter{iterend}_trial{i}.csv'\n",
    "        if os.path.isfile(outfile):\n",
    "            continue\n",
    "\n",
    "        dfi = df_info.copy()\n",
    "        dfi['Value'] = final_solutions_array[i, indexp]\n",
    "\n",
    "        # Ensure heightCanopyTop is greater than heightCanopyBottom\n",
    "        if 'heightCanopyTop' in dfi['Parameter'].values:\n",
    "            height_canopy_top_value = dfi[dfi['Parameter'] == 'heightCanopyTop']['Value'].values[0]\n",
    "\n",
    "            if height_canopy_top_value <= height_canopy_bottom_value:\n",
    "                # Adjust heightCanopyTop to be greater than heightCanopyBottom\n",
    "                height_canopy_top_value = height_canopy_bottom_value + 0.5  # Add a buffer (e.g., 1.0)\n",
    "                dfi.loc[dfi['Parameter'] == 'heightCanopyTop', 'Value'] = height_canopy_top_value\n",
    "                print(f\"Adjusted heightCanopyTop to {height_canopy_top_value} for basin {basin_id}\")\n",
    "        \n",
    "        # dfi.to_csv(outfile, index=False)\n",
    "\n",
    "    print('finish basin', basin_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37c3409f-5708-46ed-b2cf-6cf493714f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01013500'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682f7454-6a26-4d6e-96c9-dc14b6f7b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55142556]\n",
      "[0.48702536]\n",
      "[-0.2321801]\n"
     ]
    }
   ],
   "source": [
    "print(ga_all_outputs)\n",
    "print(em_model.predict(xlb_mean[np.newaxis,:]))\n",
    "print(em_model.predict(xub_mean[np.newaxis,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d63219-9246-4c22-a815-33da02dabe1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9999883 ,  0.99972449,  0.99997361, -0.99854994,  0.99999612,\n",
       "         0.94011305,  0.43063684,  0.9998742 ,  0.99970505,  0.99984253,\n",
       "        -0.07839594,  0.89211014,  0.99999751,  0.99994814,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_all_solutions / xlb_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262e6932-e06e-42f2-93b4-d075d9ab02fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/guoqiang/tmp/ipykernel_30120/2064160181.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  final_solutions_array[0] / xlb_mean_test[0]\n",
      "/glade/derecho/scratch/guoqiang/tmp/ipykernel_30120/2064160181.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  final_solutions_array[0] / xlb_mean_test[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.04466429,   1.00013755,   1.00003962, 999.94575735,\n",
       "         1.00003692,   3.99747905,   2.13702234,   1.01503781,\n",
       "         1.00058995,   1.00088219,   1.01197509,   1.32202677,\n",
       "         1.00002364,   1.00005375,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,          nan,   1.        ,\n",
       "                nan,          nan,          nan,          nan,\n",
       "               -inf,          nan,          nan,   1.        ,\n",
       "                nan,          nan,          nan,          nan])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_solutions_array[0] / xlb_mean_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9a5ba-133e-4326-8bf8-fe4bc2d8ccb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2714aa2a-aedc-4d33-9ff8-a76548c5dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37369378]\n",
      "[0.34949477]\n",
      "[-0.12512727]\n"
     ]
    }
   ],
   "source": [
    "print(ga_all_outputs)\n",
    "print(em_model.predict(xlb_mean[np.newaxis,:]))\n",
    "print(em_model.predict(xub_mean[np.newaxis,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb921590-c807-4ae0-b630-473cee5a7c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99831824,  0.90915221,  0.63204818, -0.99095851,  0.99609719,\n",
       "         0.94458203,  0.51997078,  0.94249149,  0.96941596,  0.94608948,\n",
       "         0.6835617 ,  0.98975169,  0.97918253,  0.99982075,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_all_solutions / xlb_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "347a7e7e-946b-4901-b84e-ce89f17e665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/guoqiang/tmp/ipykernel_73482/2064160181.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  final_solutions_array[0] / xlb_mean_test[0]\n",
      "/glade/derecho/scratch/guoqiang/tmp/ipykernel_73482/2064160181.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  final_solutions_array[0] / xlb_mean_test[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  7.42185295,   1.04535723,   1.55239305, 996.15129491,\n",
       "         1.03709946,   3.77379634,   1.95862182,   7.87453187,\n",
       "         1.06117427,   1.30202385,   1.0035139 ,   1.03058889,\n",
       "         1.19752615,   1.00018578,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,   1.        ,   1.        ,\n",
       "         1.        ,   1.        ,          nan,   1.        ,\n",
       "                nan,          nan,          nan,          nan,\n",
       "               -inf,          nan,          nan,   1.        ,\n",
       "                nan,          nan,          nan,          nan])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_solutions_array[0] / xlb_mean_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a0af025-cd50-4f24-b2ce-c7a9ce13e88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.30585882e+03, 1.82431461e+00, 1.04333292e+00, 1.70681383e+01,\n",
       "       1.87172973e+00, 3.56465756e+00, 1.94973650e+00, 1.59393645e+01,\n",
       "       1.08627072e+00, 1.16833937e+00, 1.00627789e+00, 1.00476224e+00,\n",
       "       1.01632847e+00, 1.04614266e+00])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/glade/campaign/cgd/tss/people/mozhgana/projects/SUMMA_Calib/param_sets_LSEspaceCV_1test/01013500/paramset_iter1_trial0.csv')\n",
    "df['Value'].values / df['Lower'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4919610f-3ed4-4d82-a3b7-d580db5a5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_att_use_train2 = df_att_use_train.drop(['hru_id'], axis=1)\n",
    "\n",
    "    xlb_mean_train = np.nan * np.zeros([len(df_param_lb_train), len(inputnames)])\n",
    "    xub_mean_train = np.nan * np.zeros([len(df_param_ub_train), len(inputnames)])   \n",
    "    for i in range(len(df_param_lb_train)):\n",
    "        param_lb_mean = df_param_lb_train.values[i, :]\n",
    "        param_ub_mean = df_param_ub_train.values[i, :]\n",
    "        attrvalues = df_att_use_train2.values[i,:]\n",
    "        xlb_mean_train[i,:] = np.hstack([param_lb_mean, attrvalues])\n",
    "        xub_mean_train[i,:] = np.hstack([param_ub_mean, attrvalues])\n",
    "\n",
    "    xlb_mean_train_scaled = (xlb_mean_train - x_train_mean) / x_train_std\n",
    "    xub_mean_train_scaled = (xub_mean_train - x_train_mean) / x_train_std\n",
    "    normdict = {'method': 'z-score',\n",
    "                'mean': x_train_mean,\n",
    "                'std': x_train_std,\n",
    "               }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c7d0704-0bac-4777-bb0d-3792eea7224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09292251])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_model.predict(xlb_mean_train_scaled[[400],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e7d85d4-150a-4ab4-a4b1-46d9685e87eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.48507464279601153)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=400\n",
    "em_model.predict(x_all_scaled[i*400:(i+1)*400,:]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04091788-6bc2-4ecb-8299-2d596353b7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PytorchEnv]",
   "language": "python",
   "name": "conda-env-PytorchEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
