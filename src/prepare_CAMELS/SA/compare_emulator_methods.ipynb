{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19f740e-f179-47a9-95df-312f5ac06c39",
   "metadata": {},
   "source": [
    "# Check the sensitivity of one basin\n",
    "Compare the performance of different emulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6767673a-0b8e-4e76-b455-6c872a1ed4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use observed streamflow data to evaluate model outputs\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os, sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40973c7a-09eb-45c3-b289-f319a0484824",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ef44fb-1269-4d6e-b9ea-f2ade5db4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 200\n",
    "nparam = 27\n",
    "params = np.nan * np.zeros([niter, nparam])\n",
    "\n",
    "for i in range(0, niter):\n",
    "    if i>=0:\n",
    "        file = f'/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/SA_HH_allbasins/level1/param_sets/paramset_iter0_trial{i}.pkl'\n",
    "    else:\n",
    "        file = f'/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/SA_HH_allbasins/level1/param_sets/all_default_parameters.pkl' # -1: default paramters\n",
    "        \n",
    "    df_param = pd.read_pickle(file)\n",
    "    va = df_param['Value'].values\n",
    "    for j in range(nparam):\n",
    "        params[i, j]=np.mean(va[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ced101ea-a4ad-48d6-a704-71dd56d9e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrid = 627\n",
    "outpath = '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/SA_HH_allbasins/level1/ctsm_outputs_evaluation'\n",
    "kge = np.nan * np.zeros([niter, ngrid])\n",
    "for t in range(0, niter): # -1 is default\n",
    "    # outfile metric\n",
    "    outfile_metric = f'{outpath}/metric_iter0_trial{t}.csv'\n",
    "    df_metric = pd.read_csv(outfile_metric)\n",
    "    kge[t, :] = df_metric['KGEmod'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "457b00a6-250c-4811-bf7e-e6c2434a9113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((179, 627), (179, 27))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ~np.isnan(kge[:,0])\n",
    "kge = kge[index,:]\n",
    "params = params[index,:]\n",
    "kge.shape, params.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e61d8-3b58-4287-8f21-bcad440aab43",
   "metadata": {},
   "source": [
    "# Emulator comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee1a478f-2ac0-4faf-a49b-17e549c808ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "runbasin = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a36a1f-1fcd-48db-9cac-0ec09f6c2725",
   "metadata": {},
   "source": [
    "## random forest\n",
    "Normalization Not Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f835ce4-5089-4576-ba67-d63a9585d073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing basin 0\n",
      "mean cv_scores_rf -0.017916634159768952\n",
      "CPU times: user 5.97 s, sys: 16 ms, total: 5.99 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming `kge` and `params` are your datasets with shapes (179, 627) and (179, 27), respectively\n",
    "\n",
    "# Split the kge dataset into 627 separate arrays, one for each basin\n",
    "# Note: This step assumes `kge` is accessible as a numpy array or similar\n",
    "kge_per_basin = np.split(kge, 627, axis=1)  # This splits along the second axis, resulting in 627 (179, 1) arrays\n",
    "\n",
    "# Initialize a list to hold the cross-validation scores for each model/basin\n",
    "cv_scores_rf = []\n",
    "\n",
    "# For each basin, train a model and evaluate its performance using cross-validation\n",
    "for basin_idx, kge_basin in enumerate(kge_per_basin):\n",
    "    if np.mod(basin_idx, 50) == 0:\n",
    "        print('processing basin', basin_idx)\n",
    "        \n",
    "    # Initialize the Random Forest regressor\n",
    "    model = RandomForestRegressor()\n",
    "    \n",
    "    # Perform 5-fold cross-validation and store the mean score\n",
    "    # Note: Adjust cv=5 to change the number of folds\n",
    "    # Negative mean squared error is used as the scoring parameter; adjust as needed\n",
    "    scores = cross_val_score(model, params, np.ravel(kge_basin), cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    # Store the mean score for this basin's model\n",
    "    cv_scores_rf.append(mean_score)\n",
    "    \n",
    "    # # Optional: Print progress\n",
    "    # print(f\"Basin {basin_idx+1}: CV Score = {mean_score}\")\n",
    "\n",
    "    if basin_idx > runbasin:\n",
    "        break\n",
    "\n",
    "# cv_scores_rf now contains the cross-validation score for each basin's model\n",
    "cv_scores_rf = np.array(cv_scores_rf)\n",
    "print('mean cv_scores_rf', np.nanmean(cv_scores_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6b430-d2d7-42ce-96c0-8feea6793e42",
   "metadata": {},
   "source": [
    "## Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0287ca0-dda2-4fe2-a400-ef51d3441d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing basin 0\n",
      "Mean CV scores GPR with normalization and Matérn kernel: -0.018103963008820403\n",
      "CPU times: user 6.76 s, sys: 8.45 ms, total: 6.77 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C, Matern\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `kge` and `params` are already loaded\n",
    "\n",
    "# Split the kge dataset into 627 separate arrays, one for each basin\n",
    "kge_per_basin = np.split(kge, 627, axis=1)\n",
    "\n",
    "# Initialize a list to hold the cross-validation scores for each model/basin\n",
    "cv_scores_gpr = []\n",
    "\n",
    "# Define a kernel for the Gaussian Process using the Matérn kernel\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)\n",
    "\n",
    "for basin_idx, kge_basin in enumerate(kge_per_basin):\n",
    "    \n",
    "    if np.mod(basin_idx, 50) == 0:\n",
    "        print('processing basin', basin_idx)\n",
    "        \n",
    "    # Create a pipeline with normalization and GPR\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "    pipeline = Pipeline([('normalize', MinMaxScaler()), ('gpr', gp)])\n",
    "    \n",
    "    # Perform 5-fold cross-validation and store the mean score\n",
    "    scores = cross_val_score(pipeline, params, np.ravel(kge_basin), cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    # Store the mean score for this basin's model\n",
    "    cv_scores_gpr.append(mean_score)\n",
    "\n",
    "    # For demonstration, limit the number of basins processed\n",
    "    if basin_idx > 2:  # Adjust this to process more or fewer basins\n",
    "        break\n",
    "\n",
    "cv_scores_gpr = np.array(cv_scores_gpr)\n",
    "print('Mean CV scores GPR with normalization and Matérn kernel:', np.nanmean(cv_scores_gpr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f619f39d-881d-4260-a161-5b098ac6d56e",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcf23c0c-75cb-48f4-8ba1-15ec8b371032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing basin 0\n",
      "mean cv_scores_svm -0.02236118670705224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `kge` and `params` are your datasets with shapes (179, 627) and (179, 27), respectively\n",
    "\n",
    "# Split the kge dataset into 627 separate arrays, one for each basin\n",
    "kge_per_basin = np.split(kge, 627, axis=1)  # This splits along the second axis, resulting in 627 (179, 1) arrays\n",
    "\n",
    "# Initialize a list to hold the cross-validation scores for each model/basin\n",
    "cv_scores_svm = []\n",
    "\n",
    "# For each basin, train a Support Vector Regression model and evaluate its performance using cross-validation\n",
    "for basin_idx, kge_basin in enumerate(kge_per_basin):\n",
    "\n",
    "    if np.mod(basin_idx, 50) == 0:\n",
    "        print('processing basin', basin_idx)\n",
    "    \n",
    "    # Initialize the SVR model within a pipeline that includes normalization\n",
    "    svr_pipeline = make_pipeline(StandardScaler(), SVR(kernel='rbf'))\n",
    "    \n",
    "    # Perform 5-fold cross-validation and store the mean score\n",
    "    # Note: Adjust cv=5 to change the number of folds\n",
    "    # Negative mean squared error is used as the scoring parameter; adjust as needed\n",
    "    scores = cross_val_score(svr_pipeline, params, np.ravel(kge_basin), cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    # Store the mean score for this basin's model\n",
    "    cv_scores_svm.append(mean_score)\n",
    "    \n",
    "    # Optional: Print progress\n",
    "    if basin_idx > runbasin:  # Early break for demonstration purposes\n",
    "        break\n",
    "\n",
    "# cv_scores_svm now contains the cross-validation score for each basin's model\n",
    "cv_scores_svm = np.array(cv_scores_svm)\n",
    "print('mean cv_scores_svm', np.nanmean(cv_scores_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9e168-7e18-4b07-8785-4d7f278ac587",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45e6e7e3-f42a-4e2f-9315-6ce67a112d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing basin 0\n",
      "Mean CV Scores for MLP: -0.05339818461894081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `kge` and `params` are already loaded with shapes (179, 627) and (179, 27), respectively\n",
    "\n",
    "# Split the kge dataset into 627 separate arrays, one for each basin\n",
    "kge_per_basin = np.split(kge, 627, axis=1)\n",
    "\n",
    "# Initialize a list to hold the cross-validation scores for each model/basin\n",
    "cv_scores_mlp = []\n",
    "\n",
    "# Loop through each basin\n",
    "for basin_idx, kge_basin in enumerate(kge_per_basin):\n",
    "\n",
    "    if np.mod(basin_idx, 50) == 0:\n",
    "        print('processing basin', basin_idx)\n",
    "\n",
    "    # Create an MLPRegressor with adjusted parameters\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', \n",
    "                       alpha=0.001, batch_size='auto', learning_rate='adaptive', \n",
    "                       learning_rate_init=0.001, max_iter=1000, shuffle=True, \n",
    "                       random_state=1, tol=0.0001, verbose=False, early_stopping=True, \n",
    "                       validation_fraction=0.1, n_iter_no_change=10)\n",
    "    \n",
    "    # Use a pipeline to automate scaling\n",
    "    pipeline = make_pipeline(StandardScaler(), mlp)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    # Ensure kge_basin is flattened properly to match the shape of params\n",
    "    scores = cross_val_score(pipeline, params, kge_basin.flatten(), cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = np.mean(scores)\n",
    "\n",
    "    # Append the mean score to the list\n",
    "    cv_scores_mlp.append(mean_score)\n",
    "\n",
    "    # Stop early for the sake of demonstration\n",
    "    if basin_idx > runbasin:\n",
    "        break\n",
    "\n",
    "# Convert the scores list to a NumPy array for convenience\n",
    "cv_scores_mlp = np.array(cv_scores_mlp)\n",
    "print('Mean CV Scores for MLP:', np.nanmean(cv_scores_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd38f74-7fa7-4183-ba42-7eda8ef10621",
   "metadata": {},
   "source": [
    "## MO-ASMO GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fcfca52-6d92-4a2e-9f0e-e12f7aeec63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../ctsm_optz/MO-ASMO/src')\n",
    "from gp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc8cdb7f-00f1-4c08-98ad-2fc477e2a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing basin 1\n",
      "Processing basin 2\n",
      "Processing basin 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Assuming the GPR_Matern class and all necessary functions like sceua_optimizer are defined as per your code\n",
    "\n",
    "# Sample code to initialize and use the GPR_Matern with MinMaxScaler\n",
    "\n",
    "# Assuming `kge` and `params` are already loaded with shapes (179, 627) and (179, 27), respectively\n",
    "# Define the bounds for input scaling - assuming a generic 0-1 scale for illustration\n",
    "xlb = np.min(params, axis=0)\n",
    "xub = np.max(params, axis=0)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "params_scaled = scaler.fit_transform(params)  # Normalize the params\n",
    "\n",
    "# Split the kge dataset into 627 separate arrays, one for each basin\n",
    "kge_per_basin = np.split(kge, 627, axis=1)\n",
    "\n",
    "# For simplicity, demonstrating with the first few basins\n",
    "cv_scores_gpr_matern = []\n",
    "\n",
    "for basin_idx, kge_basin in enumerate(kge_per_basin):\n",
    "\n",
    "    if np.mod(basin_idx, 50) == 0:\n",
    "        print('processing basin', basin_idx)\n",
    "\n",
    "    # Initialize GPR_Matern with the scaled parameters and kge values\n",
    "    gpr_matern_model = GPR_Matern(params_scaled, kge_basin.flatten(), nInput=27, nOutput=1, N=179, xlb=xlb, xub=xub)\n",
    "    \n",
    "    # Example prediction for the same inputs\n",
    "    predictions = gpr_matern_model.predict(params_scaled)\n",
    "    \n",
    "    # Normally, you would evaluate the model's performance here\n",
    "    # Since we're not implementing a full cross-validation loop, this step is skipped\n",
    "\n",
    "    # Stop early for the sake of demonstration\n",
    "    if basin_idx > runbasin:\n",
    "        break\n",
    "\n",
    "        \n",
    "# This demonstrates how to initialize and use the GPR_Matern class with MinMaxScaler applied to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fb948e4-fc46-49ff-930a-83816c0c3292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing basin 3\n",
      "Mean CV Scores for MOASMO GPR: -0.018313445638765226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Sample data setup -- replace with your actual data\n",
    "# params = np.random.randn(179, 27)  # Example feature matrix\n",
    "# kge = np.random.randn(179, 627)    # Example target matrix\n",
    "\n",
    "n_splits = 5  # Number of folds for cross-validation\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Assuming the bounds for the GPR_Matern class are known\n",
    "xlb = np.min(params, axis=0)\n",
    "xub = np.max(params, axis=0)\n",
    "\n",
    "cv_scores_mgpr = []\n",
    "\n",
    "# Process each basin separately\n",
    "for basin_index in range(kge.shape[1]):\n",
    "\n",
    "    if np.mod(basin_index, 50) == 0:\n",
    "        print('processing basin', basin_index)\n",
    "        \n",
    "    basin_scores = []\n",
    "    y = kge[:, basin_index]\n",
    "\n",
    "    for train_index, test_index in kf.split(params):\n",
    "        X_train, X_test = params[train_index], params[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Initialize and fit the GPR_Matern model\n",
    "        model = GPR_Matern(X_train, y_train, nInput=27, nOutput=1, N=len(train_index), xlb=xlb, xub=xub)\n",
    "        \n",
    "        # Predict using the fitted model\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate the negative mean squared error\n",
    "        score = -mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        basin_scores.append(score)\n",
    "    \n",
    "    # Output the average score for the basin\n",
    "    avg_score = np.mean(basin_scores)\n",
    "\n",
    "    # Append the mean score to the list\n",
    "    cv_scores_mgpr.append(avg_score)\n",
    "    \n",
    "    # Stop early for the sake of demonstration\n",
    "    if basin_index > runbasin:\n",
    "        break\n",
    "\n",
    "# Convert the scores list to a NumPy array for convenience\n",
    "cv_scores_mgpr = np.array(cv_scores_mgpr)\n",
    "print('Mean CV Scores for MOASMO GPR:', np.nanmean(cv_scores_mgpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62e017-bc10-4588-a07b-f379e4aafb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2024a",
   "language": "python",
   "name": "npl-2024a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
