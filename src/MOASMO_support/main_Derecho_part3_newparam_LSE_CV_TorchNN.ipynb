{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90140c5-6a50-456d-b816-88af72bb3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, subprocess, time, toml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from MOASMO_parameter_allbasin_emulator import allbasin_emulator_CV_traintest_and_optimize_2_ann\n",
    "import run_multiple_paramsets_Derecho\n",
    "from multiprocessing import Pool\n",
    "\n",
    "iter_end = 1 # e.g., iter_end=2 means outputs from iter0 and iter1 will be used to generate new paprameters for iter 2\n",
    "ncpus = 5\n",
    "# ncpus = 20\n",
    "# iterend = 1\n",
    "numruns = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442bd0e6-2fb3-40e1-91fe-82dc5dafb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "only_checkruns = False\n",
    "\n",
    "infile_basin_info = f\"/glade/work/guoqiang/CTSM_CAMELS/data_mesh_surf/HillslopeHydrology/CAMELS_level1_basin_info.csv\"\n",
    "infile_param_info = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/src/parameter/CTSM_CAMELS_calibparam_2410.csv'\n",
    "infile_attr_foruse = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/data/camels_attributes_table_TrainModel.csv'\n",
    "inpath_moasmo = \"/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator\"\n",
    "path_CTSM_case_all = f'/glade/work/guoqiang/CTSM_CAMELS/Calib_HH_emulator'\n",
    "\n",
    "# trainmode = 'trainbasin' # allbasin; trainbasin\n",
    "# trainmode = 'allbasin_2err'\n",
    "trainmode = 'spaceCV1'\n",
    "# trainmode = 'allbasin_50iter0'\n",
    "# trainmode = 'allbasin'\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# train on what basins?\n",
    "\n",
    "if trainmode == 'allbasin':\n",
    "    target_index = np.arange(627)\n",
    "    suffix = 'LSEnormKGE'\n",
    "    outpathname = 'LSE_allbasin'\n",
    "    objfunc = 'normKGE'\n",
    "elif trainmode == 'spaceCV1':\n",
    "    test_index = np.arange(0, 627, 5)\n",
    "    train_index = np.setdiff1d(np.arange(627), test_index)\n",
    "    target_index = train_index\n",
    "    outpathname = 'LSE_normNN_normKGECV0'\n",
    "    suffix = 'LSEnormNNnormKGECV0'\n",
    "    objfunc = 'normKGE'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34193e73-663b-465f-99cb-11b68512a7c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# check whether runs are finished and merge output csv/pkl files\n",
    "def check_runs_and_merge(tarbasin, iter_end, numruns, path_CTSM_case_all, suffix):\n",
    "    config_file = f'{path_CTSM_case_all}/configuration/_level1-{tarbasin}_config_MOASMO.toml'\n",
    "    config = toml.load(config_file)\n",
    "\n",
    "    path_CTSM_base = config['path_CTSM_case']\n",
    "    if config['path_calib'] == 'NA':\n",
    "        path_MOASMOcalib = f'{path_CTSM_base}_calib'\n",
    "    else:\n",
    "        path_MOASMOcalib = config['path_calib']\n",
    "    path_archive = f'{path_MOASMOcalib}/ctsm_outputs_{suffix}'\n",
    "        \n",
    "    os.makedirs(path_MOASMOcalib, exist_ok=True) \n",
    "\n",
    "    # check whether runs are finished and merge output csv/pkl files\n",
    "    num_init = config['num_init'] # initial number of samples\n",
    "    # num_per_iter = config['num_per_iter'] # number of selected pareto parameter sets for each iteration\n",
    "    num_per_iter = numruns\n",
    "    for it in range(0, iter_end):\n",
    "        if it == 0:\n",
    "            sample_num = num_init\n",
    "        else:\n",
    "            sample_num = num_per_iter\n",
    "        file_metric_iter, file_param_iter = run_multiple_paramsets_Derecho.check_if_all_runs_are_finsihed(path_archive, it, sample_num)\n",
    "    return (tarbasin, file_metric_iter, file_param_iter)\n",
    "\n",
    "def parallel_check_and_merge(iter_end, ncpus, numruns, infile_param_info, infile_attr_foruse, inpath_moasmo, path_CTSM_case_all, target_index, suffix):\n",
    "    # Create a pool of workers\n",
    "    with Pool(processes=ncpus) as pool:\n",
    "        # Prepare the arguments for each process\n",
    "        args = [(tarbasin, iter_end, numruns, path_CTSM_case_all, suffix) for tarbasin in target_index]\n",
    "        \n",
    "        # Run the processes in parallel\n",
    "        results = pool.starmap(check_runs_and_merge, args)\n",
    "        \n",
    "        # Process the results if needed\n",
    "        for result in results:\n",
    "            tarbasin, file_metric_iter, file_param_iter = result\n",
    "            print(f\"Processed basin {tarbasin}: {file_metric_iter}, {file_param_iter}\")\n",
    "\n",
    "# parallel_check_and_merge(iter_end, ncpus, numruns, infile_param_info, infile_attr_foruse, inpath_moasmo, path_CTSM_case_all, target_index, suffix)\n",
    "\n",
    "if only_checkruns == True:\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8c0cb4-1515-46bd-ab79-ed13f6688f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/camels_basin_attribute_train_LSEnormNNnormKGECV0.pkl\n",
      "File exists: /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/camels_basin_attribute_test_LSEnormNNnormKGECV0.pkl\n",
      "The number of attributes used: 27\n",
      "['mean_elev', 'mean_slope', 'area_gauges2', 'p_mean', 'pet_mean', 'aridity', 'p_seasonality', 'frac_snow', 'high_prec_freq', 'high_prec_dur', 'low_prec_freq', 'low_prec_dur', 'frac_forest', 'lai_max', 'lai_diff', 'dom_land_cover', 'dom_land_cover_frac', 'soil_depth_pelletier', 'soil_depth_statsgo', 'soil_porosity', 'soil_conductivity', 'max_water_content', 'sand_frac', 'silt_frac', 'clay_frac', 'carbonate_rocks_frac', 'geol_permeability']\n",
      "Number of nan samples: 1079\n",
      "Number of original parameter sets: 100200\n",
      "Number of final parameter sets: 99121\n",
      "Convert dom_land_cover to one-hot encoding\n",
      "New columns: ['dom_land_cover_0', 'dom_land_cover_1', 'dom_land_cover_2', 'dom_land_cover_3', 'dom_land_cover_4', 'dom_land_cover_5', 'dom_land_cover_6', 'dom_land_cover_7', 'dom_land_cover_8', 'dom_land_cover_9', 'dom_land_cover_10', 'dom_land_cover_11']\n",
      "Input shape: (99121, 54)\n",
      "Train/test model\n",
      "Train index: [  1   2   3   4   6   7   8   9  11  12  13  14  16  17  18  19  21  22\n",
      "  23  24  26  27  28  29  31  32  33  34  36  37  38  39  41  42  43  44\n",
      "  46  47  48  49  51  52  53  54  56  57  58  59  61  62  63  64  66  67\n",
      "  68  69  71  72  73  74  76  77  78  79  81  82  83  84  86  87  88  89\n",
      "  91  92  93  94  96  97  98  99 101 102 103 104 106 107 108 109 111 112\n",
      " 113 114 116 117 118 119 121 122 123 124 126 127 128 129 131 132 133 134\n",
      " 136 137 138 139 141 142 143 144 146 147 148 149 151 152 153 154 156 157\n",
      " 158 159 161 162 163 164 166 167 168 169 171 172 173 174 176 177 178 179\n",
      " 181 182 183 184 186 187 188 189 191 192 193 194 196 197 198 199 201 202\n",
      " 203 204 206 207 208 209 211 212 213 214 216 217 218 219 221 222 223 224\n",
      " 226 227 228 229 231 232 233 234 236 237 238 239 241 242 243 244 246 247\n",
      " 248 249 251 252 253 254 256 257 258 259 261 262 263 264 266 267 268 269\n",
      " 271 272 273 274 276 277 278 279 281 282 283 284 286 287 288 289 291 292\n",
      " 293 294 296 297 298 299 301 302 303 304 306 307 308 309 311 312 313 314\n",
      " 316 317 318 319 321 322 323 324 326 327 328 329 331 332 333 334 336 337\n",
      " 338 339 341 342 343 344 346 347 348 349 351 352 353 354 356 357 358 359\n",
      " 361 362 363 364 366 367 368 369 371 372 373 374 376 377 378 379 381 382\n",
      " 383 384 386 387 388 389 391 392 393 394 396 397 398 399 401 402 403 404\n",
      " 406 407 408 409 411 412 413 414 416 417 418 419 421 422 423 424 426 427\n",
      " 428 429 431 432 433 434 436 437 438 439 441 442 443 444 446 447 448 449\n",
      " 451 452 453 454 456 457 458 459 461 462 463 464 466 467 468 469 471 472\n",
      " 473 474 476 477 478 479 481 482 483 484 486 487 488 489 491 492 493 494\n",
      " 496 497 498 499 501 502 503 504 506 507 508 509 511 512 513 514 516 517\n",
      " 518 519 521 522 523 524 526 527 528 529 531 532 533 534 536 537 538 539\n",
      " 541 542 543 544 546 547 548 549 551 552 553 554 556 557 558 559 561 562\n",
      " 563 564 566 567 568 569 571 572 573 574 576 577 578 579 581 582 583 584\n",
      " 586 587 588 589 591 592 593 594 596 597 598 599 601 602 603 604 606 607\n",
      " 608 609 611 612 613 614 616 617 618 619 621 622 623 624 626]\n",
      "Use normalized KGE as output\n",
      "Epoch 1, Training Loss: 0.1271073818206787, Validation Loss: 0.11125783622264862\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 2, Training Loss: 0.11146938800811768, Validation Loss: 0.1028120368719101\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 3, Training Loss: 0.10428516566753387, Validation Loss: 0.09950383752584457\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 4, Training Loss: 0.10139182955026627, Validation Loss: 0.09773795306682587\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 5, Training Loss: 0.09938205778598785, Validation Loss: 0.09606064110994339\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 6, Training Loss: 0.09716304391622543, Validation Loss: 0.09444265812635422\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 7, Training Loss: 0.09498367458581924, Validation Loss: 0.0932203009724617\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 8, Training Loss: 0.09330207854509354, Validation Loss: 0.0925479456782341\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 9, Training Loss: 0.09231127798557281, Validation Loss: 0.09229370206594467\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 10, Training Loss: 0.0918896347284317, Validation Loss: 0.09218647330999374\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 11, Training Loss: 0.09176146239042282, Validation Loss: 0.0919874981045723\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 12, Training Loss: 0.09167110919952393, Validation Loss: 0.09157954901456833\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n",
      "Epoch 13, Training Loss: 0.09147390723228455, Validation Loss: 0.09096478670835495\n",
      "Model saved to /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/LSE_normNN_normKGECV0/ANN_emulator_for_iter1_LSEnormNNnormKGECV0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m########################################################################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# build emulator and generate outputs\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspaceCV\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m trainmode:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mallbasin_emulator_CV_traintest_and_optimize_2_ann\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfile_basin_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfile_param_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfile_attr_foruse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minpath_moasmo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutpathname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_CTSM_case_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumruns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     allbasin_emulator_train_and_optimize(infile_basin_info, infile_param_info, infile_attr_foruse, inpath_moasmo, outpathname, path_CTSM_case_all, iter_end, ncpus, target_index, suffix, numruns, objfunc)\u001b[39;00m\n",
      "File \u001b[0;32m~/CTSM_repos/CTSM_calibration/src/MOASMO_support/MOASMO_parameter_allbasin_emulator.py:1462\u001b[0m, in \u001b[0;36mallbasin_emulator_CV_traintest_and_optimize_2_ann\u001b[0;34m(infile_basin_info, infile_param_info, infile_attr_foruse, inpath_moasmo, outpathname, path_CTSM_case, iterend, ncpus, suffix, train_index, numruns, objfunc)\u001b[0m\n\u001b[1;32m   1460\u001b[0m     \u001b[38;5;66;03m# Train a random forest emulator\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m     outfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/ANN_emulator_for_iter\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miterend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1462\u001b[0m     em_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nn_model_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1465\u001b[0m normdict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz-score\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1466\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: x_train_mean,\n\u001b[1;32m   1467\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m: x_train_std,\n\u001b[1;32m   1468\u001b[0m            }\n\u001b[1;32m   1469\u001b[0m param_names \u001b[38;5;241m=\u001b[39m df_param_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/CTSM_repos/CTSM_calibration/src/MOASMO_support/MOASMO_parameter_allbasin_emulator.py:80\u001b[0m, in \u001b[0;36mtrain_nn_model_pytorch\u001b[0;34m(x_train_scaled, y_train, x_val_scaled, y_val, n_epochs, patience, lr, model_file)\u001b[0m\n\u001b[1;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     79\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model(x_train_tensor)\n\u001b[0;32m---> 80\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     82\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/PytorchEnv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/PytorchEnv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/PytorchEnv/lib/python3.11/site-packages/torch/nn/modules/loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/PytorchEnv/lib/python3.11/site-packages/torch/nn/functional.py:3792\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m   3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[0;32m-> 3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# build emulator and generate outputs\n",
    "\n",
    "if 'spaceCV' in trainmode:\n",
    "    allbasin_emulator_CV_traintest_and_optimize_2_ann(infile_basin_info, infile_param_info, infile_attr_foruse, inpath_moasmo, outpathname, path_CTSM_case_all, iter_end, ncpus, suffix, train_index, numruns=numruns, objfunc=objfunc)\n",
    "\n",
    "# else:\n",
    "#     allbasin_emulator_train_and_optimize(infile_basin_info, infile_param_info, infile_attr_foruse, inpath_moasmo, outpathname, path_CTSM_case_all, iter_end, ncpus, target_index, suffix, numruns, objfunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9534c-5f36-4ae8-bd03-ab21f2e3f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test basins\n",
    "for tarbasin in test_index:\n",
    "    config_file = f'{path_CTSM_case_all}/configuration/_level1-{tarbasin}_config_MOASMO.toml'\n",
    "    config = toml.load(config_file)\n",
    "    \n",
    "    # inputs\n",
    "    file_parameter_list = config['file_calib_param']\n",
    "    path_CTSM_base = config['path_CTSM_case']\n",
    "    path_script_MOASMO = config['path_script_MOASMO']\n",
    "    path_CTSM_source = config['path_CTSM_source']\n",
    "    ref_streamflow = config['file_Qobs']\n",
    "    \n",
    "    if 'add_flow_file' in config:\n",
    "        add_flow_file = config['add_flow_file']\n",
    "    else:\n",
    "        add_flow_file = 'NA'\n",
    "    \n",
    "    script_singlerun = f'{path_script_MOASMO}/run_one_paramset_Derecho.py'\n",
    "    script_clone = f'{path_CTSM_source}/cime/scripts/create_clone'\n",
    "\n",
    "    if config['path_calib'] == 'NA':\n",
    "        path_MOASMOcalib = f'{path_CTSM_base}_calib'\n",
    "    else:\n",
    "        path_MOASMOcalib = config['path_calib']\n",
    "        \n",
    "    # outputs\n",
    "    path_paramset = f'{path_MOASMOcalib}/param_sets_{suffix}test'\n",
    "    path_submit = f'{path_MOASMOcalib}/run_model_{suffix}test'\n",
    "    path_archive = f'{path_MOASMOcalib}/ctsm_outputs_{suffix}test'\n",
    "        \n",
    "    os.makedirs(path_MOASMOcalib, exist_ok=True) \n",
    "    \n",
    "    # evaluation period\n",
    "    RUN_STARTDATE = config['RUN_STARTDATE']\n",
    "    ignore_month = config['ignore_month']\n",
    "    STOP_OPTION = config['STOP_OPTION']\n",
    "    STOP_N = config['STOP_N']\n",
    "    \n",
    "    if 'nonstandard_evaluation' in config:\n",
    "        nonstandard_evaluation = config['nonstandard_evaluation']\n",
    "    else:\n",
    "        nonstandard_evaluation = 'NA'\n",
    "    \n",
    "    # HPC job settings\n",
    "    job_mode = config['job_mode']\n",
    "    job_CTSMiteration = config['job_CTSMiteration']\n",
    "    # job_controlMOASMO = config['job_controlMOASMO'] # not needed here\n",
    "    \n",
    "    date_start = (pd.Timestamp(RUN_STARTDATE) + pd.offsets.DateOffset(months=ignore_month)).strftime('%Y-%m-%d') # ignor the first year when evaluating model\n",
    "    if STOP_OPTION == 'nyears':\n",
    "        date_end = (pd.Timestamp(RUN_STARTDATE) + pd.offsets.DateOffset(years=STOP_N)).strftime('%Y-%m-%d')\n",
    "    elif STOP_OPTION == 'nmonths':\n",
    "        date_end = (pd.Timestamp(RUN_STARTDATE) + pd.offsets.DateOffset(months=STOP_N)).strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        sys.exit(f'STOP_OPTION must be nyears or nmonths. {STOP_OPTION} is not accepted.')\n",
    "\n",
    "    # generate submission commands (note, this won't submit a real job on Derecho)\n",
    "    run_multiple_paramsets_Derecho.generate_and_submit_multi_CTSM_runs(iter_end, path_submit, path_paramset, path_CTSM_base, \n",
    "                                                                       path_archive, script_singlerun, script_clone, \n",
    "                                                                       date_start, date_end, ref_streamflow, add_flow_file,\n",
    "                                                                       job_CTSMiteration, job_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e9c4d-a935-49fc-8c48-240cbc4ba79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b497b-f625-400b-bc3b-15f5fc5ecfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PytorchEnv]",
   "language": "python",
   "name": "conda-env-PytorchEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
