{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60649dc-fa81-499a-af52-1f027b8ad8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MOASMO_parameter_allbasin_emulator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2833bdb6-277a-4a90-83ee-0ab379915971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/emulator_CV_test/camels_basin_attribute_train_CV1.pkl\n",
      "File exists: /glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/emulator_CV_test/camels_basin_attribute_test_CV1.pkl\n",
      "The number of attributes used: 27\n",
      "['mean_elev', 'mean_slope', 'area_gauges2', 'p_mean', 'pet_mean', 'aridity', 'p_seasonality', 'frac_snow', 'high_prec_freq', 'high_prec_dur', 'low_prec_freq', 'low_prec_dur', 'frac_forest', 'lai_max', 'lai_diff', 'dom_land_cover', 'dom_land_cover_frac', 'soil_depth_pelletier', 'soil_depth_statsgo', 'soil_porosity', 'soil_conductivity', 'max_water_content', 'sand_frac', 'silt_frac', 'clay_frac', 'carbonate_rocks_frac', 'geol_permeability']\n"
     ]
    }
   ],
   "source": [
    "    infile_basin_info = f\"/glade/work/guoqiang/CTSM_CAMELS/data_mesh_surf/HillslopeHydrology/CAMELS_level1_basin_info.csv\"\n",
    "    infile_param_info = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/src/parameter/CTSM_CAMELS_calibparam_2410.csv'\n",
    "    infile_attr_foruse = '/glade/u/home/guoqiang/CTSM_repos/CTSM_calibration/data/camels_attributes_table_TrainModel.csv'\n",
    "    inpath_moasmo = \"/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator\"\n",
    "    outpathname = \"emulator_CV_test\"\n",
    "    path_CTSM_case = f'/glade/work/guoqiang/CTSM_CAMELS/Calib_HH_emulator'\n",
    "    train_index = np.setdiff1d(np.arange(627), np.arange(0, 627, 5))\n",
    "    numruns=100\n",
    "    objfunc='normKGE'\n",
    "    ncpus = 1\n",
    "    iterend = 1\n",
    "    suffix = 'CV1'\n",
    "    suffix_defa_source = 'LSEnormKGE' # temporary suffix if CV1 has not been generated\n",
    "\n",
    "\n",
    "    outpath = f\"{inpath_moasmo}/{outpathname}\"\n",
    "    os.makedirs(outpath, exist_ok=True)\n",
    "\n",
    "    # Load data: same for all iterations\n",
    "    df_basin_info = pd.read_csv(infile_basin_info)\n",
    "    df_basin_info.index = np.arange(len(df_basin_info))\n",
    "    all_index = np.arange(len(df_basin_info))\n",
    "\n",
    "    test_index = np.setdiff1d(all_index, train_index)\n",
    "\n",
    "    # information for all basins\n",
    "    df_param_info = pd.read_csv(infile_param_info)\n",
    "\n",
    "    file_defa_param = f'{outpath}/camels_ctsm_defa_param_train_{suffix}.csv'\n",
    "    df_param_defa_train = read_allbasin_defa_params(path_CTSM_case, infile_param_info, file_defa_param, train_index)\n",
    "    file_defa_param = f'{outpath}/camels_ctsm_defa_param_test_{suffix}.csv'\n",
    "    df_param_defa_test = read_allbasin_defa_params(path_CTSM_case, infile_param_info, file_defa_param, test_index)\n",
    "\n",
    "    file_param_lb = f'{outpath}/camels_ctsm_all_param_lb_train_{suffix}.gz'\n",
    "    file_param_ub = f'{outpath}/camels_ctsm_all_param_ub_train_{suffix}.gz'\n",
    "    \n",
    "    df_param_lb_train, df_param_ub_train = load_basin_param_bounds(inpath_moasmo, df_param_defa_train, file_param_lb, file_param_ub, train_index, suffix_defa_source)\n",
    "    file_param_lb = f'{outpath}/camels_ctsm_all_param_lb_test_{suffix}.gz'\n",
    "    file_param_ub = f'{outpath}/camels_ctsm_all_param_ub_test_{suffix}.gz'\n",
    "    df_param_lb_test, df_param_ub_test = load_basin_param_bounds(inpath_moasmo, df_param_defa_test, file_param_lb, file_param_ub, test_index, suffix_defa_source)\n",
    "\n",
    "    \n",
    "    file_camels_attribute = f'{outpath}/camels_basin_attribute_train_{suffix}.pkl'\n",
    "    df_att_train = read_camels_attributes(infile_basin_info, file_camels_attribute, train_index)\n",
    "    file_camels_attribute = f'{outpath}/camels_basin_attribute_test_{suffix}.pkl'\n",
    "    df_att_test = read_camels_attributes(infile_basin_info, file_camels_attribute, test_index)\n",
    "\n",
    "    df_att_foruse = pd.read_csv(infile_attr_foruse)\n",
    "    useattrs = list(df_att_foruse[df_att_foruse['att_Xie2021'].values]['Attribute_text'].values)\n",
    "    print(\"The number of attributes used:\", len(useattrs))\n",
    "    print(useattrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a7d17c5-d56c-4899-bc14-b32057c7d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan samples: 1079\n",
      "Number of original parameter sets: 100200\n",
      "Number of final parameter sets: 99121\n"
     ]
    }
   ],
   "source": [
    "    # Load data: outputs from each iteration from training basins\n",
    "    for iter in range(0, iterend):\n",
    "        file_all_param = f'{outpath}/camels_ctsm_all_param_train_{suffix}_iter{iter}.gz'\n",
    "        file_all_metric = f'{outpath}/camels_ctsm_all_metric_train_{suffix}_iter{iter}.gz'\n",
    "        file_all_basinid = f'{outpath}/camels_ctsm_all_basinid_train_{suffix}_iter{iter}.gz'\n",
    "\n",
    "        df_param_i, df_metric_i, df_basinid_i = load_all_basin_params_metrics(inpath_moasmo, df_param_defa_train,\n",
    "                                                                              df_basin_info, iter, file_all_param,\n",
    "                                                                              file_all_metric, file_all_basinid,\n",
    "                                                                              train_index, suffix_defa_source)\n",
    "\n",
    "        df_basinid_i['iter'] = iter\n",
    "\n",
    "        if iter == 0:\n",
    "            df_param = df_param_i\n",
    "            df_metric = df_metric_i\n",
    "            df_basinid = df_basinid_i\n",
    "        else:\n",
    "            df_param = pd.concat([df_param, df_param_i])\n",
    "            df_metric = pd.concat([df_metric, df_metric_i])\n",
    "            df_basinid = pd.concat([df_basinid, df_basinid_i])\n",
    "\n",
    "    df_param.index = np.arange(len(df_param))\n",
    "    df_metric.index = np.arange(len(df_metric))\n",
    "    df_basinid.index = np.arange(len(df_basinid))\n",
    "\n",
    "    index = np.isnan(np.sum(df_metric.values, axis=1) + np.sum(df_param.values, axis=1))\n",
    "    df_param = df_param[~index]\n",
    "    df_metric = df_metric[~index]\n",
    "    df_basinid = df_basinid[~index]\n",
    "\n",
    "    df_param.index = np.arange(len(df_param))\n",
    "    df_metric.index = np.arange(len(df_metric))\n",
    "    df_basinid.index = np.arange(len(df_basinid))\n",
    "\n",
    "    print('Number of nan samples:', np.sum(index))\n",
    "    print(\"Number of original parameter sets:\", len(index))\n",
    "    print(\"Number of final parameter sets:\", len(df_param))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51090f3d-a4dc-465d-817f-4c068d7bd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert dom_land_cover to one-hot encoding\n",
      "New columns: ['dom_land_cover_0', 'dom_land_cover_1', 'dom_land_cover_2', 'dom_land_cover_3', 'dom_land_cover_4', 'dom_land_cover_5', 'dom_land_cover_6', 'dom_land_cover_7', 'dom_land_cover_8', 'dom_land_cover_9', 'dom_land_cover_10', 'dom_land_cover_11']\n",
      "Input shape: (99121, 54)\n",
      "Train/test model\n",
      "Train index: [  1   2   3   4   6   7   8   9  11  12  13  14  16  17  18  19  21  22\n",
      "  23  24  26  27  28  29  31  32  33  34  36  37  38  39  41  42  43  44\n",
      "  46  47  48  49  51  52  53  54  56  57  58  59  61  62  63  64  66  67\n",
      "  68  69  71  72  73  74  76  77  78  79  81  82  83  84  86  87  88  89\n",
      "  91  92  93  94  96  97  98  99 101 102 103 104 106 107 108 109 111 112\n",
      " 113 114 116 117 118 119 121 122 123 124 126 127 128 129 131 132 133 134\n",
      " 136 137 138 139 141 142 143 144 146 147 148 149 151 152 153 154 156 157\n",
      " 158 159 161 162 163 164 166 167 168 169 171 172 173 174 176 177 178 179\n",
      " 181 182 183 184 186 187 188 189 191 192 193 194 196 197 198 199 201 202\n",
      " 203 204 206 207 208 209 211 212 213 214 216 217 218 219 221 222 223 224\n",
      " 226 227 228 229 231 232 233 234 236 237 238 239 241 242 243 244 246 247\n",
      " 248 249 251 252 253 254 256 257 258 259 261 262 263 264 266 267 268 269\n",
      " 271 272 273 274 276 277 278 279 281 282 283 284 286 287 288 289 291 292\n",
      " 293 294 296 297 298 299 301 302 303 304 306 307 308 309 311 312 313 314\n",
      " 316 317 318 319 321 322 323 324 326 327 328 329 331 332 333 334 336 337\n",
      " 338 339 341 342 343 344 346 347 348 349 351 352 353 354 356 357 358 359\n",
      " 361 362 363 364 366 367 368 369 371 372 373 374 376 377 378 379 381 382\n",
      " 383 384 386 387 388 389 391 392 393 394 396 397 398 399 401 402 403 404\n",
      " 406 407 408 409 411 412 413 414 416 417 418 419 421 422 423 424 426 427\n",
      " 428 429 431 432 433 434 436 437 438 439 441 442 443 444 446 447 448 449\n",
      " 451 452 453 454 456 457 458 459 461 462 463 464 466 467 468 469 471 472\n",
      " 473 474 476 477 478 479 481 482 483 484 486 487 488 489 491 492 493 494\n",
      " 496 497 498 499 501 502 503 504 506 507 508 509 511 512 513 514 516 517\n",
      " 518 519 521 522 523 524 526 527 528 529 531 532 533 534 536 537 538 539\n",
      " 541 542 543 544 546 547 548 549 551 552 553 554 556 557 558 559 561 562\n",
      " 563 564 566 567 568 569 571 572 573 574 576 577 578 579 581 582 583 584\n",
      " 586 587 588 589 591 592 593 594 596 597 598 599 601 602 603 604 606 607\n",
      " 608 609 611 612 613 614 616 617 618 619 621 622 623 624 626]\n"
     ]
    }
   ],
   "source": [
    "    # One-hot encoding for categorical attributes\n",
    "    df_att = pd.concat([df_att_train, df_att_test])\n",
    "    df_att.index = np.arange(len(df_att))\n",
    "    df_att_use = df_att[useattrs + [\"hru_id\"]]\n",
    "    for att in useattrs:\n",
    "        if df_att_use[att].dtype == \"object\":\n",
    "            print('Convert', att, 'to one-hot encoding')\n",
    "            enc = OneHotEncoder(sparse=False)\n",
    "            enc.fit(df_att_use[[att]])\n",
    "            encnames = [att + \"_\" + str(i) for i in range(len(enc.categories_[0]))]\n",
    "            print('New columns:', encnames)\n",
    "            df_enc = pd.DataFrame(enc.transform(df_att_use[[att]]), columns=encnames)\n",
    "            df_att_use = pd.concat([df_att_use, df_enc], axis=1)\n",
    "            df_att_use = df_att_use.drop([att], axis=1)\n",
    "\n",
    "    df_att_use_train = df_att_use[:len(df_att_train)]\n",
    "    df_att_use_test = df_att_use[:len(df_att_test)]\n",
    "    df_att_use_train.index = np.arange(len(df_att_use_train))\n",
    "    df_att_use_test.index = np.arange(len(df_att_use_test))\n",
    "    \n",
    "    useattrs = list(df_att_use_train.columns)\n",
    "    useattrs.remove('hru_id')\n",
    "\n",
    "    # Prepare model input and output\n",
    "    df_input = df_param.copy()\n",
    "    df_input[\"hru_id\"] = df_basinid[\"hru_id\"]\n",
    "    df_input = df_input.merge(df_att_use_train[useattrs + [\"hru_id\"]], on=\"hru_id\", how=\"left\")\n",
    "    df_input = df_input.drop([\"hru_id\"], axis=1)\n",
    "\n",
    "    inputnames = list(df_param.columns) + useattrs\n",
    "    x_all = df_input[inputnames].values.copy()\n",
    "    print(\"Input shape:\", x_all.shape)\n",
    "\n",
    "    print('Train/test model')\n",
    "    print('Train index:', train_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa5b92e9-cb9b-4f9a-8cec-ebecdb2fb88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use normalized KGE as output\n"
     ]
    }
   ],
   "source": [
    "    if objfunc == 'normKGE':\n",
    "        print('Use normalized KGE as output')\n",
    "        df_output = df_metric.copy()\n",
    "        y_all = df_output[[\"kge\"]].values.copy()\n",
    "        y_all = y_all / (2 - y_all)  # Normalize KGE\n",
    "\n",
    "        # Train a random forest emulator\n",
    "        outfile = f'{outpath}/RF_emulator_for_iter{iterend}_{suffix}.pkl'\n",
    "        if os.path.isfile(outfile):\n",
    "            with open(outfile, 'rb') as file:\n",
    "                em_model = pickle.load(file)\n",
    "        else:\n",
    "            modelconfig = {'n_estimators': 100, 'random_state': 42, 'max_depth': 40}\n",
    "            em_model = RandomForestRegressor(**modelconfig, n_jobs=ncpus)\n",
    "            em_model.fit(x_all[::100,:], y_all[::100])\n",
    "            with open(outfile, 'wb') as file:\n",
    "                pickle.dump(em_model, file)\n",
    "\n",
    "\n",
    "    elif objfunc == 'norm2err':\n",
    "        print('Use normalized mae and mmae as output')\n",
    "        # normalization is performed for each basin\n",
    "        df_output = df_metric.copy()\n",
    "        metvalues = df_output[['mae', 'max_mon_abs_err']].values.copy()\n",
    "        y_all = np.nan * metvalues\n",
    "        for i in range(len(train_index)):\n",
    "            indi = df_basinid['basin_id'].values == train_index[i]\n",
    "            di = metvalues[indi, :]\n",
    "            di = (di - np.nanmin(di, axis=0)) / (np.nanmax(di, axis=0) - np.nanmin(di, axis=0))\n",
    "            y_all[indi, :] = di\n",
    "\n",
    "        # Train a random forest emulator\n",
    "        outfile = f'{outpath}/RF_emulator_2errOBJfunc_for_iter{iterend}_{suffix}.pkl'\n",
    "        outfile_eval = f'{outpath}/RF_emulator_2errOBJfunc_for_iter{iterend}_{suffix}_eval.npz'\n",
    "        if os.path.isfile(outfile):\n",
    "            with open(outfile, 'rb') as file:\n",
    "                em_model = pickle.load(file)\n",
    "        else:\n",
    "            modelconfig = {'n_estimators': 200, 'random_state': 42, 'max_depth': 40}\n",
    "            em_model = RandomForestRegressor(**modelconfig, n_jobs=ncpus)\n",
    "            em_model.fit(x_all, y_all)\n",
    "            with open(outfile, 'wb') as file:\n",
    "                pickle.dump(em_model, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f504272e-0043-4ebe-86a1-dd463246a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_objfunc: 1\n",
      "Error processing basin 1-0: [Errno 2] No such file or directory: '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/level1_1_calib/param_sets_CV1/paramset_iter0_trial0.pkl'\n",
      "num_objfunc: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/CTSM_repos/CTSM_calibration/src/MOASMO_support/MOASMO_parameter_allbasin_emulator.py:395\u001b[0m, in \u001b[0;36mparallel_process_basins\u001b[0;34m(df_basinid, df_param_lb, df_param_ub, x_all, df_input, y_all, param_names, inputnames, em_model, inpath_moasmo, ncpus, numruns, iterend, basin_index, suffix)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mncpus) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 395\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_basin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03mApply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03min a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m param_names \u001b[38;5;241m=\u001b[39m df_param_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m----> 2\u001b[0m \u001b[43mparallel_process_basins\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_basinid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_param_lb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_param_ub_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mx_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mparam_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mem_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minpath_moasmo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CTSM_repos/CTSM_calibration/src/MOASMO_support/MOASMO_parameter_allbasin_emulator.py:394\u001b[0m, in \u001b[0;36mparallel_process_basins\u001b[0;34m(df_basinid, df_param_lb, df_param_ub, x_all, df_input, y_all, param_names, inputnames, em_model, inpath_moasmo, ncpus, numruns, iterend, basin_index, suffix)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_process_basins\u001b[39m(df_basinid, df_param_lb, df_param_ub, x_all, df_input, y_all, param_names, inputnames, em_model, inpath_moasmo, ncpus, numruns, iterend, basin_index, suffix):\n\u001b[1;32m    392\u001b[0m     args \u001b[38;5;241m=\u001b[39m [(basin_index[tarbasin_id], tarbasin_id, df_basinid, df_param_lb, df_param_ub, x_all, df_input, y_all, param_names, inputnames, em_model, inpath_moasmo, numruns, iterend, suffix) \u001b[38;5;28;01mfor\u001b[39;00m tarbasin_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(basin_index))]\n\u001b[0;32m--> 394\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncpus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_basin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py:739\u001b[0m, in \u001b[0;36mPool.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 739\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py:657\u001b[0m, in \u001b[0;36mPool.terminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    655\u001b[0m util\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterminating pool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m TERMINATE\n\u001b[0;32m--> 657\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_terminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/util.py:224\u001b[0m, in \u001b[0;36mFinalize.__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     sub_debug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinalizer calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and kwargs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    223\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[0;32m--> 224\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weakref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    226\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py:695\u001b[0m, in \u001b[0;36mPool._terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, change_notifier, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    692\u001b[0m task_handler\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m TERMINATE\n\u001b[1;32m    694\u001b[0m util\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelping task handler/workers to finish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_help_stuff_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43minqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_handler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m result_handler\u001b[38;5;241m.\u001b[39mis_alive()) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(cache) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have cache with result_hander not alive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/pool.py:677\u001b[0m, in \u001b[0;36mPool._help_stuff_finish\u001b[0;34m(inqueue, task_handler, size)\u001b[0m\n\u001b[1;32m    675\u001b[0m inqueue\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m task_handler\u001b[38;5;241m.\u001b[39mis_alive() \u001b[38;5;129;01mand\u001b[39;00m inqueue\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mpoll():\n\u001b[0;32m--> 677\u001b[0m     \u001b[43minqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/connection.py:437\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxsize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;241m>\u001b[39m maxsize:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/guoqiang/conda-envs/npl-2024a-tgq/lib/python3.11/multiprocessing/connection.py:395\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 395\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    396\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    param_names = df_param_info['Parameter'].values\n",
    "    parallel_process_basins(df_basinid, df_param_lb_train, df_param_ub_train,\n",
    "                            x_all, df_input, y_all,\n",
    "                            param_names, inputnames, em_model, inpath_moasmo, ncpus, numruns, iterend, train_index, suffix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53fd1e25-e8d1-4204-9acb-38c21fea307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing basin 0-0: [Errno 2] No such file or directory: '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/level1_0_calib/param_sets_CV1test/paramset_iter0_trial0.pkl'\n",
      "Error processing basin 5-1: [Errno 2] No such file or directory: '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/level1_5_calib/param_sets_CV1test/paramset_iter0_trial0.pkl'\n",
      "Error processing basin 10-2: [Errno 2] No such file or directory: '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/level1_10_calib/param_sets_CV1test/paramset_iter0_trial0.pkl'\n",
      "Error processing basin 15-3: [Errno 2] No such file or directory: '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/level1_15_calib/param_sets_CV1test/paramset_iter0_trial0.pkl'\n",
      "Error processing basin 20-4: [Errno 2] No such file or directory: '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/level1_20_calib/param_sets_CV1test/paramset_iter0_trial0.pkl'\n",
      "Error processing basin 25-5: [Errno 2] No such file or directory: '/glade/campaign/cgd/tss/people/guoqiang/CTSM_CAMELS_proj/Calib_HH_emulator/level1_25_calib/param_sets_CV1test/paramset_iter0_trial0.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    #### predict parameter in unseen basins\n",
    "    suffixtest = suffix+'test'\n",
    "    numruns_test = numruns # can be smaller\n",
    "    if objfunc == 'normKGE':\n",
    "        num_objfunc=1\n",
    "    else:\n",
    "        sys.exit('Not tested objfunc')\n",
    "\n",
    "    df_att_use_test2 = df_att_use_test.drop(['hru_id'], axis=1)\n",
    "\n",
    "    xlb_mean_test = np.nan * np.zeros([len(df_param_lb_test), len(inputnames)])\n",
    "    xub_mean_test = np.nan * np.zeros([len(df_param_ub_test), len(inputnames)])   \n",
    "    for i in range(len(df_param_lb_test)):\n",
    "        param_lb_mean = df_param_lb_test.values[i, :]\n",
    "        param_ub_mean = df_param_ub_test.values[i, :]\n",
    "        attrvalues = df_att_use_test2.values[i,:]\n",
    "        xlb_mean_test[i,:] = np.hstack([param_lb_mean, attrvalues])\n",
    "        xub_mean_test[i,:] = np.hstack([param_ub_mean, attrvalues])\n",
    "    \n",
    "    parallel_process_basins_predictunseen(xlb_mean_test, xub_mean_test, param_names, em_model, inpath_moasmo, ncpus, numruns_test, iterend, test_index, suffixtest, num_objfunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf244c15-448c-4559-9304-e421b288aeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:npl-2024a-tgq]",
   "language": "python",
   "name": "conda-env-npl-2024a-tgq-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
