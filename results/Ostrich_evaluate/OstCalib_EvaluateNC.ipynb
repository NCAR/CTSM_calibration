{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bd39b8-da75-4e07-8c87-152755f37769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guoqiang Tang\n",
    "# Note: Here the average of outputs is used to compare to observed streamflow\n",
    "# Those functions are taken from Ostrich support scripts, with minor modification\n",
    "# Evaluate by reading streamflow from Netcdf files\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import sys, glob, os, re, subprocess\n",
    "\n",
    "# turn off all warnings (not always necessary)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "########################################################################################################################\n",
    "# define functions for calculating metrics\n",
    "\n",
    "def ismember(a, b):\n",
    "    bind = {}\n",
    "    for i, elt in enumerate(b):\n",
    "        if elt not in bind:\n",
    "            bind[elt] = i\n",
    "    ind = np.array([bind.get(itm, np.nan) for itm in a])\n",
    "    ind1 = np.where(~np.isnan(ind))[0]\n",
    "    ind2 = ind[ind1]\n",
    "    return ind1.astype(int), ind2.astype(int) # None can be replaced by any other \"not in b\" value\n",
    "\n",
    "def get_modified_KGE(obs,sim):\n",
    "    sim[sim<0] = np.nan\n",
    "    obs[obs<0] = np.nan\n",
    "    ind = (~np.isnan(obs)) & (~np.isnan(sim))\n",
    "    obs = obs[ind]\n",
    "    sim = sim[ind]\n",
    "\n",
    "    try:\n",
    "        sd_sim=np.std(sim, ddof=1)\n",
    "        sd_obs=np.std(obs, ddof=1)\n",
    "        m_sim=np.mean(sim)\n",
    "        m_obs=np.mean(obs)\n",
    "        r=(np.corrcoef(sim,obs))[0,1]\n",
    "        relvar=(float(sd_sim)/float(m_sim))/(float(sd_obs)/float(m_obs))\n",
    "        bias=float(m_sim)/float(m_obs)\n",
    "        kge=1.0-np.sqrt((r-1)**2 +(relvar-1)**2 + (bias-1)**2)\n",
    "    except:\n",
    "        kge = np.nan\n",
    "\n",
    "    return kge\n",
    "\n",
    "\n",
    "def get_RMSE(obs,sim):\n",
    "    sim[sim<0] = np.nan\n",
    "    obs[obs<0] = np.nan\n",
    "    rmse = np.sqrt(np.nanmean(np.power((sim - obs),2)))\n",
    "    return rmse\n",
    "\n",
    "def get_mean_error(obs,sim):\n",
    "    bias_err = np.nanmean(sim - obs)\n",
    "    abs_err = np.nanmean(np.absolute(sim - obs))\n",
    "    return bias_err, abs_err\n",
    "\n",
    "########################################################################################################################\n",
    "# define functions for reading CTSM outputs\n",
    "\n",
    "def get_target_archive_files_from_starchive(pathCTSM, keyword):\n",
    "    # get the list of archived files of the latest model run\n",
    "    # # settings\n",
    "    # pathCTSM = '/glade/work/guoqiang/CTSM_cases/CAMELS_Calib/CAMELS_LumpCalib'\n",
    "    # keyword = \".clm2.h1.\"\n",
    "    # find files\n",
    "    st_archive_files = glob.glob(f'{pathCTSM}/st_archive.*')\n",
    "    st_archive_files.sort()\n",
    "    st_archive_files = st_archive_files[-1]\n",
    "    filelist = []\n",
    "    print('Getting simulaiton outputs from CTSM model case path ...')\n",
    "    print('pathCTSM:', pathCTSM)\n",
    "    print('keyword:', keyword)\n",
    "    with open(st_archive_files, 'r')  as f:\n",
    "        for line in f:\n",
    "            if line.startswith('moving') or line.startswith('copying'):\n",
    "                if keyword in line:\n",
    "                    file = line.split(' to ')[-1].strip()\n",
    "                    if os.path.isfile(file):\n",
    "                        print('Append to file list:', file)\n",
    "                        filelist.append(file)\n",
    "                    else:\n",
    "                        sys.exit(f'File does not exist: {file}')\n",
    "    return filelist\n",
    "\n",
    "\n",
    "def get_target_archive_files_from_archivefolder(pathCTSM, keyword):\n",
    "    # get the list of archived files of the latest model run\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(pathCTSM)\n",
    "    out = subprocess.run('./xmlquery DOUT_S_ROOT', shell=True, capture_output=True)\n",
    "    DOUT_S_ROOT = out.stdout.decode().strip().split(' ')[-1]\n",
    "    os.chdir(cwd)\n",
    "    filelist = glob.glob(f'{DOUT_S_ROOT}/lnd/hist/*{keyword}*')\n",
    "    filelist.sort()\n",
    "    return filelist\n",
    "\n",
    "\n",
    "def main_read_CTSM_streamflow(pathCTSM, CTSMfilelist, date_start, date_end, clm_q_name, clm_q_sdim):\n",
    "    ########################################################################################################################\n",
    "    # read files\n",
    "    ds_simu = xr.open_mfdataset(CTSMfilelist)\n",
    "    ds_simu = ds_simu[[clm_q_name]]\n",
    "\n",
    "    if date_start == 'default' or date_end == 'default':\n",
    "        print(\n",
    "            'Either date_start or date_end is default. Evaluation period will be the overlapped period of referene data and simulations')\n",
    "    else:\n",
    "        ds_simu = ds_simu.sel(time=slice(date_start, date_end))\n",
    "\n",
    "    ds_simu = ds_simu.load()\n",
    "\n",
    "    # change time format\n",
    "    ds_simu['time'] = ds_simu.indexes['time'].to_datetimeindex()\n",
    "\n",
    "    ########################################################################################################################\n",
    "    # get the area of a basin to convert the unit of QRUNOFF from mm/s to m3/s\n",
    "\n",
    "    # elementArea is in radians^2, not real area\n",
    "    # cwd = os.getcwd()\n",
    "    # os.chdir(pathCTSM)\n",
    "    # out = subprocess.run('./xmlquery LND_DOMAIN_MESH', shell=True, capture_output=True)\n",
    "    # LND_DOMAIN_MESH = out.stdout.decode().strip().split(' ')[-1]\n",
    "    # os.chdir(cwd)\n",
    "\n",
    "    # get surface data file from user_nl_clm or lnd_in. user_nl_clm may not be reliable because it may not contain this file\n",
    "    # file = f'{pathCTSM}/user_nl_clm'\n",
    "    file = f'{pathCTSM}/Buildconf/clmconf/lnd_in'\n",
    "    fsurdat = ''\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('fsurdat'):\n",
    "                fsurdat = line.split('=')[-1].strip()\n",
    "                fsurdat = fsurdat.replace('\\'', '')\n",
    "\n",
    "    if not os.path.isfile(fsurdat):\n",
    "        sys.exit(f'File not found! fsurdat: {fsurdat}')\n",
    "\n",
    "    with xr.open_dataset(fsurdat) as ds_surdat:\n",
    "        area = ds_surdat.AREA.values\n",
    "\n",
    "    # calculate streamflow: although mean is used, for Sean's setting, only one basin should be allowed effective in the calibration\n",
    "    # streamflow? Use mean for this test\n",
    "    ds_simu[clm_q_name].values = (ds_simu[clm_q_name].values / 1000) * (\n",
    "                area * 1e6)  # raw q: mm/s; raw area km2; target: m3/s\n",
    "    ds_simu = ds_simu.mean(dim=clm_q_sdim, skipna=True)\n",
    "\n",
    "    return ds_simu\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "# define functions for reading CAMELS data\n",
    "\n",
    "def read_CAMELS_Q(file_Qobs):\n",
    "    df_q_in = pd.read_csv(file_Qobs, delim_whitespace=True, header=None)\n",
    "    years = df_q_in[1].values\n",
    "    months = df_q_in[2].values\n",
    "    days = df_q_in[3].values\n",
    "    dates = [f'{years[i]}-{months[i]:02}-{days[i]:02}' for i in range(len(years))]\n",
    "    q_obs = df_q_in[4].values * 0.028316847  # cfs to cms\n",
    "    q_obs[q_obs < 0] = -9999.0\n",
    "    df_q_out = pd.DataFrame({'Date': dates, 'Runoff_cms': q_obs})\n",
    "    return df_q_out\n",
    "\n",
    "def read_CAMELS_Q_and_to_xarray(ref_streamflow, ref_q_date, ref_q_name):\n",
    "    ########################################################################################################################\n",
    "    # load observation streamflow\n",
    "    print('Use streamflow reference file:', ref_streamflow)\n",
    "    df_q_obs = pd.read_csv(ref_streamflow)\n",
    "    ds_q_obs = xr.Dataset()\n",
    "    ds_q_obs.coords['time'] = pd.to_datetime(df_q_obs[ref_q_date].values)\n",
    "    ds_q_obs[ref_q_name] = xr.DataArray(df_q_obs[ref_q_name].values, dims=['time']) # flexible time\n",
    "    for i in range(10000):\n",
    "        coli = ref_q_name + str(i)\n",
    "        if coli in df_q_obs.columns:\n",
    "            ds_q_obs[coli] = xr.DataArray(df_q_obs[coli].values, dims=['time'])  # flexible time\n",
    "        else:\n",
    "            break\n",
    "    return ds_q_obs\n",
    "\n",
    "\n",
    "\n",
    "def add_upstream_flow(add_flow_file, ds_simu, ref_q_date, ref_q_name, clm_q_name):\n",
    "    ########################################################################################################################\n",
    "    # add upstream flows to simulated streamflow\n",
    "\n",
    "    add_flow_file = [f for f in add_flow_file.split(',') if len(f)>0]\n",
    "    if len(add_flow_file) > 0:\n",
    "        add_flow_file2 = []\n",
    "        for f in add_flow_file:\n",
    "            if not os.path.isfile(f):\n",
    "                print('File does not exist:', f)\n",
    "                print('Remove it from add flow file list')\n",
    "            else:\n",
    "                add_flow_file2.append(f)\n",
    "        add_flow_file = add_flow_file2\n",
    "\n",
    "    if len(add_flow_file) > 0:\n",
    "        print('Flow files will be added to the incremental downstream basin:', add_flow_file)\n",
    "        q_dd = np.zeros(len(ds_simu.time))\n",
    "        num = np.zeros(len(ds_simu.time))\n",
    "        time0 = ds_simu.time.values\n",
    "        for i in range(len(add_flow_file)):\n",
    "            df_addi = read_CAMELS_Q(add_flow_file[i])\n",
    "            # df_addi = pd.read_csv(add_flow_file[i])\n",
    "            timei = pd.to_datetime(df_addi[ref_q_date].values)\n",
    "            ind1, ind2 = ismember(np.array(timei), time0)\n",
    "            q_dd[ind2] = q_dd[ind2] + df_addi[ref_q_name].values[ind1]\n",
    "            num[ind2] = num[ind2] + 1\n",
    "        q_dd[num==0] = np.nan\n",
    "\n",
    "        ds_simu[clm_q_name].values = ds_simu[clm_q_name].values + q_dd\n",
    "        ratio = np.sum(~np.isnan(ds_simu[clm_q_name].values)) / len(ds_simu[clm_q_name].values)\n",
    "        if ratio < 0.5:\n",
    "            print('Warning!!!')\n",
    "        print(f'The valid ratio of simulated streamflow is {ratio} after add upstream flow')\n",
    "\n",
    "    return ds_simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b30dfa3-cd09-4f03-905c-2c33030515aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use streamflow reference file: /glade/campaign/cgd/tss/people/guoqiang/CTSMcases/CAMELS_Calib/Calib_all_HH_Ostrich/level1_1_Ostrich/refdata/streamflow_data.csv\n",
      "0.5427395894565246 16.086715843731316\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################################################################################################################\n",
    "# input arguments\n",
    "# future improvements can use more advanced argparse. currently, only sys is used\n",
    "\n",
    "basin = 'level1_1'\n",
    "\n",
    "######## required input arguments\n",
    "pathCTSM = f'/glade/work/guoqiang/CTSM_cases/CAMELS_Calib/Calib_all_HH_Ostrich/{basin}'\n",
    "# path_archive = f'/glade/campaign/cgd/tss/people/guoqiang/CTSMcases/CAMELS_Calib/Calib_all_HH_Ostrich/{basin}_Ostrich/archive/PreserveModelOutput/Run_58'\n",
    "# path_archive = f'/glade/campaign/cgd/tss/people/guoqiang/CTSMcases/CAMELS_Calib/Calib_all_HH_Ostrich/{basin}_Ostrich/archive/PreserveBestModel/'\n",
    "# path_archive = f'/glade/campaign/cgd/tss/people/guoqiang/CTSMcases/CAMELS_Calib/Calib_all_HH_Ostrich/{basin}_Ostrich/archive/Bestsimu1/'\n",
    "path_archive = f'/glade/campaign/cgd/tss/people/guoqiang/CTSMcases/CAMELS_Calib/Calib_all_HH_Ostrich/{basin}_Ostrich/archive/DefaultSimu'\n",
    "\n",
    "date_start = '2009-10-01'\n",
    "date_end = '2014-10-01'\n",
    "\n",
    "# reference files (streamflow, snow cover). if a file cannot be found, it won't be inclulded in the calibration\n",
    "ref_streamflow = f'/glade/campaign/cgd/tss/people/guoqiang/CTSMcases/CAMELS_Calib/Calib_all_HH_Ostrich/{basin}_Ostrich/refdata/streamflow_data.csv'\n",
    "\n",
    "# add_flow_file. sometimes upstream flow needs to be added to the incremental downstream area runoff\n",
    "add_flow_file = ''\n",
    "\n",
    "\n",
    "######## default variable names\n",
    "clm_q_name = 'QRUNOFF' # default runoff variable name\n",
    "clm_q_sdim = 'lndgrid' # spatial dim name\n",
    "ref_q_name = 'Runoff_cms'\n",
    "ref_q_date = 'Date'\n",
    "keyword = \".clm2.h1.\"\n",
    "\n",
    "########################################################################################################################\n",
    "# load CTSM streamflow (m3/s)\n",
    "CTSMfilelist = glob.glob(f'{path_archive}/*.h1.*.nc')\n",
    "CTSMfilelist.sort()\n",
    "ds_simu = main_read_CTSM_streamflow(pathCTSM, CTSMfilelist, date_start, date_end, clm_q_name, clm_q_sdim)\n",
    "\n",
    "########################################################################################################################\n",
    "# load CAMELS observation streamflow (m3/s)\n",
    "ds_q_obs = read_CAMELS_Q_and_to_xarray(ref_streamflow, ref_q_date, ref_q_name)\n",
    "\n",
    "########################################################################################################################\n",
    "# add upstream flows to simulated streamflow\n",
    "ds_simu = add_upstream_flow(add_flow_file, ds_simu, ref_q_date, ref_q_name, clm_q_name)\n",
    "\n",
    "########################################################################################################################\n",
    "# evaluation\n",
    "\n",
    "ds_q_obs = ds_q_obs.sel(time=ds_q_obs.time.isin(ds_simu.time))\n",
    "ds_simu = ds_simu.sel(time=ds_simu.time.isin(ds_q_obs.time))\n",
    "\n",
    "kge_q = get_modified_KGE(obs=ds_q_obs[ref_q_name].values, sim=ds_simu[clm_q_name].values)\n",
    "rmse_q = get_RMSE(obs=ds_q_obs[ref_q_name].values, sim=ds_simu[clm_q_name].values)\n",
    "\n",
    "print(kge_q, rmse_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136df4c3-d831-4e53-9ac2-332e678aa745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
